{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import regex as re\n",
    "import os\n",
    "from pathlib import Path\n",
    "import utils_laramie\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_all_raw_data(dirpath = Path('raw_data/')):\n",
    "#     csv_list = [filename for filename in os.listdir(dirpath)]\n",
    "#     return csv_list\n",
    "# def clean_col_names(list_dfs, list_csvs):\n",
    "\n",
    "#     list_cols = [df.columns.to_list() for df in list_dfs]\n",
    "#     zipped = zip(list_csvs,list_cols)\n",
    "#     name_list = []\n",
    "#     column_list = []\n",
    "#     for tup in list(zipped):\n",
    "#         name = tup[0]\n",
    "#         match = re.match(r'(\\w+)_',name)\n",
    "#         name = match.group(1)\n",
    "#         for col in tup[1]:\n",
    "#             if name.lower() != col.lower():\n",
    "#                 name_list.append((name.upper()+'_'+col.lower()))\n",
    "#             else:\n",
    "#                 name_list.append(name.upper())\n",
    "\n",
    "#     return name_list\n",
    "\n",
    "# def drop_unnamed(df):\n",
    "#     for col in df.columns:\n",
    "#         if 'Unnamed' in str(col):\n",
    "#             df.drop(columns= col, inplace=True)\n",
    "#     return df\n",
    "    \n",
    "# def get_df(list_of_csvs= ['SPY_data.csv','TR_data.csv','VIX_data.csv']):\n",
    "#     \"\"\"concat a list of csvs into a single df\"\"\"\n",
    "#     # make a list of dataframes\n",
    "#     list_dfs = [pd.read_csv(f'raw_data/{_csv}', parse_dates = True, infer_datetime_format = True) for _csv in list_of_csvs]\n",
    "#     for df in list_dfs:\n",
    "#         df.drop_duplicates(inplace=True)\n",
    "#         df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "#         df['date'] = pd.to_datetime(df['date'])\n",
    "#         df = drop_unnamed(df)\n",
    "#     clean_headers = clean_col_names(list_dfs,list_of_csvs)\n",
    "#     merged_df = pd.concat(list_dfs, axis=1, join= 'inner')\n",
    "#     merged_df.columns = clean_headers\n",
    "#     return merged_df\n",
    "# x = get_df()\n",
    "# x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_df(list_of_csvs= ['SPY_data.csv','TR_data.csv','VIX_data.csv']):\n",
    "#     \"\"\"concat a list of csvs into a single df\"\"\"\n",
    "#     list_dfs = [pd.read_csv(f'raw_data/{_csv}', parse_dates = True, infer_datetime_format = True) for _csv in list_of_csvs]\n",
    "#     for df in list_dfs:\n",
    "#         df.drop_duplicates(inplace=True)\n",
    "#         df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "#         df['date'] = pd.to_datetime(df['date'])\n",
    "#         df = drop_unnamed(df)\n",
    "#         df.set_index('date',inplace=True)\n",
    "#     clean_headers = clean_col_names(list_dfs,list_of_csvs)\n",
    "#     merged_df = pd.concat(list_dfs, axis=1, join= 'inner')  \n",
    "#     merged_df.columns = clean_headers\n",
    "#     return merged_df\n",
    "# x = get_df()\n",
    "# x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for creating dataframe\n",
    "from utils_laramie import get_df, get_all_raw_data\n",
    "\n",
    "# imports for getting weekly range\n",
    "from utils_laramie import calc_weekly_range\n",
    "\n",
    "#imports for grouping data into weekly windows\n",
    "from utils_laramie import grp_y_wk_d, drop_off_weeks\n",
    "\n",
    "#shape data\n",
    "from utils_laramie import get_X_y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Weekly Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_day_names(df):    \n",
    "#     df = get_df(get_all_raw_data())\n",
    "#     df.reset_index(inplace=True)\n",
    "#     df['DayOfWeek'] = df['date'].dt.day_name()\n",
    "#     df.set_index('date', inplace=True)\n",
    "#     return df\n",
    "\n",
    "# def calc_weekly_range(df):\n",
    "#     \"\"\" Must run \"get_day_names\" first\"\"\"\n",
    "#     week_high = 0  \n",
    "#     week_low = 9999999\n",
    "#     for index, row in df.iterrows():\n",
    "#         if df.loc[index, 'DayOfWeek'] == 'Monday':\n",
    "#             week_high = df.loc[index,'SPY_high']\n",
    "#             week_low = df.loc[index,'SPY_low']\n",
    "#         else: \n",
    "#             if df.loc[index,'SPY_high'] > week_high:\n",
    "#                 week_high=df.loc[index,'SPY_high']\n",
    "#             if df.loc[index,'SPY_low'] < week_low:\n",
    "#                 week_low=df.loc[index,'SPY_low']\n",
    "#             if df.loc[index,'DayOfWeek'] == 'Friday':\n",
    "#                 df.loc[index,'weekly_range'] = week_high - week_low\n",
    "#     return df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_open</th>\n",
       "      <th>SPY_high</th>\n",
       "      <th>SPY_low</th>\n",
       "      <th>SPY_close</th>\n",
       "      <th>SPY_volume</th>\n",
       "      <th>SPY_trade_count</th>\n",
       "      <th>SPY_vwap</th>\n",
       "      <th>TR</th>\n",
       "      <th>VIX_open</th>\n",
       "      <th>VIX_high</th>\n",
       "      <th>VIX_low</th>\n",
       "      <th>VIX_close</th>\n",
       "      <th>weekly_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209.20</td>\n",
       "      <td>209.7295</td>\n",
       "      <td>207.20</td>\n",
       "      <td>208.27</td>\n",
       "      <td>102027111.0</td>\n",
       "      <td>374705.0</td>\n",
       "      <td>208.276128</td>\n",
       "      <td>2.5295</td>\n",
       "      <td>15.65</td>\n",
       "      <td>17.18</td>\n",
       "      <td>15.58</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>206.48</td>\n",
       "      <td>208.2890</td>\n",
       "      <td>205.78</td>\n",
       "      <td>206.99</td>\n",
       "      <td>103372367.0</td>\n",
       "      <td>387782.0</td>\n",
       "      <td>206.966276</td>\n",
       "      <td>2.5090</td>\n",
       "      <td>17.69</td>\n",
       "      <td>18.33</td>\n",
       "      <td>16.52</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206.20</td>\n",
       "      <td>208.6800</td>\n",
       "      <td>204.18</td>\n",
       "      <td>205.33</td>\n",
       "      <td>162401537.0</td>\n",
       "      <td>586210.0</td>\n",
       "      <td>206.034646</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>18.05</td>\n",
       "      <td>20.13</td>\n",
       "      <td>15.72</td>\n",
       "      <td>19.61</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205.44</td>\n",
       "      <td>207.4300</td>\n",
       "      <td>205.14</td>\n",
       "      <td>205.86</td>\n",
       "      <td>116128858.0</td>\n",
       "      <td>404992.0</td>\n",
       "      <td>206.102975</td>\n",
       "      <td>2.2900</td>\n",
       "      <td>19.25</td>\n",
       "      <td>19.72</td>\n",
       "      <td>18.13</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203.38</td>\n",
       "      <td>204.1400</td>\n",
       "      <td>201.51</td>\n",
       "      <td>201.88</td>\n",
       "      <td>211173305.0</td>\n",
       "      <td>669924.0</td>\n",
       "      <td>203.150102</td>\n",
       "      <td>4.3500</td>\n",
       "      <td>21.36</td>\n",
       "      <td>25.27</td>\n",
       "      <td>20.88</td>\n",
       "      <td>24.39</td>\n",
       "      <td>8.2195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SPY_open  SPY_high  SPY_low  SPY_close   SPY_volume  SPY_trade_count  \\\n",
       "0    209.20  209.7295   207.20     208.27  102027111.0         374705.0   \n",
       "1    206.48  208.2890   205.78     206.99  103372367.0         387782.0   \n",
       "2    206.20  208.6800   204.18     205.33  162401537.0         586210.0   \n",
       "3    205.44  207.4300   205.14     205.86  116128858.0         404992.0   \n",
       "4    203.38  204.1400   201.51     201.88  211173305.0         669924.0   \n",
       "\n",
       "     SPY_vwap      TR  VIX_open  VIX_high  VIX_low  VIX_close  weekly_range  \n",
       "0  208.276128  2.5295     15.65     17.18    15.58      15.84        0.0000  \n",
       "1  206.966276  2.5090     17.69     18.33    16.52      17.60        0.0000  \n",
       "2  206.034646  4.5000     18.05     20.13    15.72      19.61        0.0000  \n",
       "3  206.102975  2.2900     19.25     19.72    18.13      19.34        0.0000  \n",
       "4  203.150102  4.3500     21.36     25.27    20.88      24.39        8.2195  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = (get_df(get_all_raw_data()))\n",
    "df = calc_weekly_range(df)\n",
    "df = grp_y_wk_d(df)\n",
    "df = drop_off_weeks(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cols = df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPY_open',\n",
       " 'SPY_high',\n",
       " 'SPY_low',\n",
       " 'SPY_close',\n",
       " 'SPY_volume',\n",
       " 'SPY_trade_count',\n",
       " 'SPY_vwap',\n",
       " 'TR',\n",
       " 'VIX_open',\n",
       " 'VIX_high',\n",
       " 'VIX_low',\n",
       " 'VIX_close',\n",
       " 'weekly_range']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_range'] = df['TR']\n",
    "df.insert(0, 'day_range', df.pop('day_range'))\n",
    "\n",
    "df['pct_change'] = (df['SPY_close']-df['SPY_open'])/df['SPY_open']\n",
    "df.insert(1, 'pct_change', df.pop('pct_change'))\n",
    "\n",
    "df['day_range_VIX'] = df['VIX_high']-df['VIX_low']\n",
    "df.insert(2, 'day_range', df.pop('day_range'))\n",
    "\n",
    "df['pct_changeVIX'] = (df['VIX_close']-df['VIX_open'])/df['SPY_open']\n",
    "df.insert(3, 'pct_changeVIX', df.pop('pct_changeVIX'))\n",
    "\n",
    "df['mean_volume'] = df['SPY_volume']/df['SPY_trade_count']\n",
    "df.insert(4, 'mean_volume', df.pop('mean_volume'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_change</th>\n",
       "      <th>SPY_open</th>\n",
       "      <th>day_range</th>\n",
       "      <th>pct_changeVIX</th>\n",
       "      <th>mean_volume</th>\n",
       "      <th>SPY_high</th>\n",
       "      <th>SPY_low</th>\n",
       "      <th>SPY_close</th>\n",
       "      <th>SPY_volume</th>\n",
       "      <th>SPY_trade_count</th>\n",
       "      <th>SPY_vwap</th>\n",
       "      <th>TR</th>\n",
       "      <th>VIX_open</th>\n",
       "      <th>VIX_high</th>\n",
       "      <th>VIX_low</th>\n",
       "      <th>VIX_close</th>\n",
       "      <th>weekly_range</th>\n",
       "      <th>day_range_VIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.004446</td>\n",
       "      <td>209.20</td>\n",
       "      <td>2.5295</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>272.286495</td>\n",
       "      <td>209.7295</td>\n",
       "      <td>207.20</td>\n",
       "      <td>208.27</td>\n",
       "      <td>102027111.0</td>\n",
       "      <td>374705.0</td>\n",
       "      <td>208.276128</td>\n",
       "      <td>2.5295</td>\n",
       "      <td>15.65</td>\n",
       "      <td>17.18</td>\n",
       "      <td>15.58</td>\n",
       "      <td>15.84</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002470</td>\n",
       "      <td>206.48</td>\n",
       "      <td>2.5090</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>266.573402</td>\n",
       "      <td>208.2890</td>\n",
       "      <td>205.78</td>\n",
       "      <td>206.99</td>\n",
       "      <td>103372367.0</td>\n",
       "      <td>387782.0</td>\n",
       "      <td>206.966276</td>\n",
       "      <td>2.5090</td>\n",
       "      <td>17.69</td>\n",
       "      <td>18.33</td>\n",
       "      <td>16.52</td>\n",
       "      <td>17.60</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.004219</td>\n",
       "      <td>206.20</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.007565</td>\n",
       "      <td>277.036449</td>\n",
       "      <td>208.6800</td>\n",
       "      <td>204.18</td>\n",
       "      <td>205.33</td>\n",
       "      <td>162401537.0</td>\n",
       "      <td>586210.0</td>\n",
       "      <td>206.034646</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>18.05</td>\n",
       "      <td>20.13</td>\n",
       "      <td>15.72</td>\n",
       "      <td>19.61</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002044</td>\n",
       "      <td>205.44</td>\n",
       "      <td>2.2900</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>286.743585</td>\n",
       "      <td>207.4300</td>\n",
       "      <td>205.14</td>\n",
       "      <td>205.86</td>\n",
       "      <td>116128858.0</td>\n",
       "      <td>404992.0</td>\n",
       "      <td>206.102975</td>\n",
       "      <td>2.2900</td>\n",
       "      <td>19.25</td>\n",
       "      <td>19.72</td>\n",
       "      <td>18.13</td>\n",
       "      <td>19.34</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007375</td>\n",
       "      <td>203.38</td>\n",
       "      <td>4.3500</td>\n",
       "      <td>0.014898</td>\n",
       "      <td>315.219794</td>\n",
       "      <td>204.1400</td>\n",
       "      <td>201.51</td>\n",
       "      <td>201.88</td>\n",
       "      <td>211173305.0</td>\n",
       "      <td>669924.0</td>\n",
       "      <td>203.150102</td>\n",
       "      <td>4.3500</td>\n",
       "      <td>21.36</td>\n",
       "      <td>25.27</td>\n",
       "      <td>20.88</td>\n",
       "      <td>24.39</td>\n",
       "      <td>8.2195</td>\n",
       "      <td>4.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pct_change  SPY_open  day_range  pct_changeVIX  mean_volume  SPY_high  \\\n",
       "0   -0.004446    209.20     2.5295       0.000908   272.286495  209.7295   \n",
       "1    0.002470    206.48     2.5090      -0.000436   266.573402  208.2890   \n",
       "2   -0.004219    206.20     4.5000       0.007565   277.036449  208.6800   \n",
       "3    0.002044    205.44     2.2900       0.000438   286.743585  207.4300   \n",
       "4   -0.007375    203.38     4.3500       0.014898   315.219794  204.1400   \n",
       "\n",
       "   SPY_low  SPY_close   SPY_volume  SPY_trade_count    SPY_vwap      TR  \\\n",
       "0   207.20     208.27  102027111.0         374705.0  208.276128  2.5295   \n",
       "1   205.78     206.99  103372367.0         387782.0  206.966276  2.5090   \n",
       "2   204.18     205.33  162401537.0         586210.0  206.034646  4.5000   \n",
       "3   205.14     205.86  116128858.0         404992.0  206.102975  2.2900   \n",
       "4   201.51     201.88  211173305.0         669924.0  203.150102  4.3500   \n",
       "\n",
       "   VIX_open  VIX_high  VIX_low  VIX_close  weekly_range  day_range_VIX  \n",
       "0     15.65     17.18    15.58      15.84        0.0000           1.60  \n",
       "1     17.69     18.33    16.52      17.60        0.0000           1.81  \n",
       "2     18.05     20.13    15.72      19.61        0.0000           4.41  \n",
       "3     19.25     19.72    18.13      19.34        0.0000           1.59  \n",
       "4     21.36     25.27    20.88      24.39        8.2195           4.39  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.drop(columns=raw_cols[:-1])\n",
    "df_clean = df[[c for c in df_clean if c not in ['weekly_range'] ] + ['weekly_range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('clean_data/basic_spy_vix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Laramie\\Desktop\\Project_Two\\Project2\\utils_laramie.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['target']= df['weekly_range'].shift(-5)\n",
      "c:\\Users\\Laramie\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\util\\_decorators.py:311: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return func(*args, **kwargs)\n",
      "c:\\Users\\Laramie\\anaconda3\\envs\\dev\\lib\\site-packages\\pandas\\core\\frame.py:4913: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "X , y = get_X_y(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MinMaxScaler3D(MinMaxScaler):\n",
    "    def fit_transform(self, X, y=None):\n",
    "        x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "        return np.reshape(super().fit_transform(x, y=y), newshape=X.shape)\n",
    "        \n",
    "    # def inverse_transform(self, X):\n",
    "    #     x = np.reshape(X, newshape=(X.shape[0]*X.shape[1], X.shape[2]))\n",
    "    #     return np.reshape(super().inverse_transform(x), newshape=X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler3D()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(157, 5, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(157, 1, 1)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train_scaled.shape)\n",
    "display(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', batch_input_shape=(None, None, X_train_scaled.shape[-1]) ))\n",
    "model.add(Dense(1, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, 1)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Input\n",
    "# from tensorflow.keras.models import Model\n",
    "# visible = Input(shape=X_train_scaled.shape[1:])\n",
    "# hidden = Dense(X_train_scaled.shape[-1])(visible)\n",
    "# model = Model(inputs=visible, outputs=hidden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 17.8139 - mse: 17.8139 - val_loss: 64.0857 - val_mse: 64.0857\n",
      "Epoch 2/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 17.7815 - mse: 17.7815 - val_loss: 64.0006 - val_mse: 64.0006\n",
      "Epoch 3/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.7531 - mse: 17.7532 - val_loss: 63.9103 - val_mse: 63.9103\n",
      "Epoch 4/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.7301 - mse: 17.7301 - val_loss: 63.7602 - val_mse: 63.7602\n",
      "Epoch 5/400\n",
      "4/4 [==============================] - 0s 12ms/step - loss: 17.7016 - mse: 17.7016 - val_loss: 63.6658 - val_mse: 63.6658\n",
      "Epoch 6/400\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 17.6791 - mse: 17.6791 - val_loss: 63.5843 - val_mse: 63.5843\n",
      "Epoch 7/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 17.6599 - mse: 17.6599 - val_loss: 63.4757 - val_mse: 63.4757\n",
      "Epoch 8/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.6347 - mse: 17.6347 - val_loss: 63.3999 - val_mse: 63.3999\n",
      "Epoch 9/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.6096 - mse: 17.6096 - val_loss: 63.3502 - val_mse: 63.3502\n",
      "Epoch 10/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.5884 - mse: 17.5884 - val_loss: 63.3188 - val_mse: 63.3188\n",
      "Epoch 11/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.5723 - mse: 17.5723 - val_loss: 63.3258 - val_mse: 63.3258\n",
      "Epoch 12/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.5508 - mse: 17.5508 - val_loss: 63.2494 - val_mse: 63.2494\n",
      "Epoch 13/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.5339 - mse: 17.5339 - val_loss: 63.0676 - val_mse: 63.0676\n",
      "Epoch 14/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.5065 - mse: 17.5065 - val_loss: 62.9528 - val_mse: 62.9528\n",
      "Epoch 15/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.4946 - mse: 17.4946 - val_loss: 62.8086 - val_mse: 62.8086\n",
      "Epoch 16/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.4692 - mse: 17.4692 - val_loss: 62.7097 - val_mse: 62.7097\n",
      "Epoch 17/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.4418 - mse: 17.4418 - val_loss: 62.6728 - val_mse: 62.6728\n",
      "Epoch 18/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.4227 - mse: 17.4227 - val_loss: 62.6822 - val_mse: 62.6822\n",
      "Epoch 19/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.4073 - mse: 17.4073 - val_loss: 62.6437 - val_mse: 62.6437\n",
      "Epoch 20/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.3834 - mse: 17.3834 - val_loss: 62.6699 - val_mse: 62.6699\n",
      "Epoch 21/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.3684 - mse: 17.3684 - val_loss: 62.6745 - val_mse: 62.6745\n",
      "Epoch 22/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.3515 - mse: 17.3515 - val_loss: 62.6516 - val_mse: 62.6516\n",
      "Epoch 23/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.3402 - mse: 17.3402 - val_loss: 62.6275 - val_mse: 62.6275\n",
      "Epoch 24/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.3329 - mse: 17.3329 - val_loss: 62.6203 - val_mse: 62.6203\n",
      "Epoch 25/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.2976 - mse: 17.2976 - val_loss: 62.4724 - val_mse: 62.4724\n",
      "Epoch 26/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.2949 - mse: 17.2949 - val_loss: 62.1933 - val_mse: 62.1933\n",
      "Epoch 27/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.2715 - mse: 17.2715 - val_loss: 61.9988 - val_mse: 61.9988\n",
      "Epoch 28/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 17.2495 - mse: 17.2495 - val_loss: 61.8641 - val_mse: 61.8641\n",
      "Epoch 29/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.2490 - mse: 17.2490 - val_loss: 61.7426 - val_mse: 61.7426\n",
      "Epoch 30/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.2180 - mse: 17.2180 - val_loss: 61.7165 - val_mse: 61.7165\n",
      "Epoch 31/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1985 - mse: 17.1985 - val_loss: 61.7223 - val_mse: 61.7223\n",
      "Epoch 32/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1998 - mse: 17.1997 - val_loss: 61.8881 - val_mse: 61.8881\n",
      "Epoch 33/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1568 - mse: 17.1568 - val_loss: 61.9739 - val_mse: 61.9739\n",
      "Epoch 34/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1656 - mse: 17.1656 - val_loss: 62.1126 - val_mse: 62.1126\n",
      "Epoch 35/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1761 - mse: 17.1761 - val_loss: 62.1407 - val_mse: 62.1407\n",
      "Epoch 36/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.1414 - mse: 17.1414 - val_loss: 62.0493 - val_mse: 62.0493\n",
      "Epoch 37/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.1345 - mse: 17.1345 - val_loss: 61.7988 - val_mse: 61.7988\n",
      "Epoch 38/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0977 - mse: 17.0977 - val_loss: 61.6734 - val_mse: 61.6734\n",
      "Epoch 39/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0808 - mse: 17.0808 - val_loss: 61.5445 - val_mse: 61.5445\n",
      "Epoch 40/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0711 - mse: 17.0711 - val_loss: 61.3666 - val_mse: 61.3666\n",
      "Epoch 41/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 17.0586 - mse: 17.0586 - val_loss: 61.2091 - val_mse: 61.2091\n",
      "Epoch 42/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0519 - mse: 17.0519 - val_loss: 61.0580 - val_mse: 61.0580\n",
      "Epoch 43/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0461 - mse: 17.0461 - val_loss: 61.0138 - val_mse: 61.0138\n",
      "Epoch 44/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0372 - mse: 17.0372 - val_loss: 60.9979 - val_mse: 60.9979\n",
      "Epoch 45/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0267 - mse: 17.0267 - val_loss: 60.9553 - val_mse: 60.9553\n",
      "Epoch 46/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 17.0117 - mse: 17.0117 - val_loss: 61.0698 - val_mse: 61.0698\n",
      "Epoch 47/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9896 - mse: 16.9896 - val_loss: 61.1069 - val_mse: 61.1069\n",
      "Epoch 48/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9770 - mse: 16.9770 - val_loss: 61.1427 - val_mse: 61.1427\n",
      "Epoch 49/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9891 - mse: 16.9891 - val_loss: 61.2228 - val_mse: 61.2228\n",
      "Epoch 50/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9882 - mse: 16.9882 - val_loss: 61.0620 - val_mse: 61.0620\n",
      "Epoch 51/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9516 - mse: 16.9516 - val_loss: 61.0816 - val_mse: 61.0816\n",
      "Epoch 52/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9447 - mse: 16.9447 - val_loss: 61.1112 - val_mse: 61.1112\n",
      "Epoch 53/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9378 - mse: 16.9378 - val_loss: 61.0844 - val_mse: 61.0844\n",
      "Epoch 54/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9322 - mse: 16.9322 - val_loss: 61.1366 - val_mse: 61.1366\n",
      "Epoch 55/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9223 - mse: 16.9223 - val_loss: 61.1149 - val_mse: 61.1149\n",
      "Epoch 56/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9150 - mse: 16.9150 - val_loss: 61.0566 - val_mse: 61.0566\n",
      "Epoch 57/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.9043 - mse: 16.9043 - val_loss: 61.0447 - val_mse: 61.0447\n",
      "Epoch 58/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.8996 - mse: 16.8996 - val_loss: 60.9508 - val_mse: 60.9508\n",
      "Epoch 59/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.9028 - mse: 16.9028 - val_loss: 60.9566 - val_mse: 60.9566\n",
      "Epoch 60/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8753 - mse: 16.8753 - val_loss: 60.7594 - val_mse: 60.7594\n",
      "Epoch 61/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8566 - mse: 16.8566 - val_loss: 60.5945 - val_mse: 60.5945\n",
      "Epoch 62/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8603 - mse: 16.8603 - val_loss: 60.4058 - val_mse: 60.4058\n",
      "Epoch 63/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8675 - mse: 16.8675 - val_loss: 60.3072 - val_mse: 60.3072\n",
      "Epoch 64/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8534 - mse: 16.8534 - val_loss: 60.3119 - val_mse: 60.3119\n",
      "Epoch 65/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8451 - mse: 16.8451 - val_loss: 60.3598 - val_mse: 60.3598\n",
      "Epoch 66/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8340 - mse: 16.8340 - val_loss: 60.4842 - val_mse: 60.4842\n",
      "Epoch 67/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.8298 - mse: 16.8298 - val_loss: 60.6611 - val_mse: 60.6611\n",
      "Epoch 68/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.8089 - mse: 16.8089 - val_loss: 60.7246 - val_mse: 60.7246\n",
      "Epoch 69/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.8056 - mse: 16.8056 - val_loss: 60.7525 - val_mse: 60.7525\n",
      "Epoch 70/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.8018 - mse: 16.8018 - val_loss: 60.7967 - val_mse: 60.7967\n",
      "Epoch 71/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7897 - mse: 16.7897 - val_loss: 60.7336 - val_mse: 60.7336\n",
      "Epoch 72/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.7853 - mse: 16.7853 - val_loss: 60.6574 - val_mse: 60.6574\n",
      "Epoch 73/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.7759 - mse: 16.7759 - val_loss: 60.5051 - val_mse: 60.5051\n",
      "Epoch 74/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.7642 - mse: 16.7642 - val_loss: 60.4040 - val_mse: 60.4040\n",
      "Epoch 75/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7767 - mse: 16.7767 - val_loss: 60.2174 - val_mse: 60.2173\n",
      "Epoch 76/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7635 - mse: 16.7635 - val_loss: 60.1408 - val_mse: 60.1408\n",
      "Epoch 77/400\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 16.7545 - mse: 16.7545 - val_loss: 60.1637 - val_mse: 60.1637\n",
      "Epoch 78/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.7462 - mse: 16.7462 - val_loss: 60.2224 - val_mse: 60.2224\n",
      "Epoch 79/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.7375 - mse: 16.7375 - val_loss: 60.2642 - val_mse: 60.2642\n",
      "Epoch 80/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7312 - mse: 16.7312 - val_loss: 60.3780 - val_mse: 60.3780\n",
      "Epoch 81/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.7320 - mse: 16.7320 - val_loss: 60.4387 - val_mse: 60.4387\n",
      "Epoch 82/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7276 - mse: 16.7276 - val_loss: 60.4003 - val_mse: 60.4003\n",
      "Epoch 83/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.7084 - mse: 16.7084 - val_loss: 60.4825 - val_mse: 60.4825\n",
      "Epoch 84/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.7188 - mse: 16.7188 - val_loss: 60.5732 - val_mse: 60.5732\n",
      "Epoch 85/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7623 - mse: 16.7623 - val_loss: 60.7004 - val_mse: 60.7004\n",
      "Epoch 86/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.7339 - mse: 16.7339 - val_loss: 60.4853 - val_mse: 60.4853\n",
      "Epoch 87/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.6993 - mse: 16.6993 - val_loss: 60.4031 - val_mse: 60.4031\n",
      "Epoch 88/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.7038 - mse: 16.7038 - val_loss: 60.2553 - val_mse: 60.2553\n",
      "Epoch 89/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6848 - mse: 16.6848 - val_loss: 60.2563 - val_mse: 60.2563\n",
      "Epoch 90/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6843 - mse: 16.6843 - val_loss: 60.2803 - val_mse: 60.2803\n",
      "Epoch 91/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6759 - mse: 16.6759 - val_loss: 60.3662 - val_mse: 60.3662\n",
      "Epoch 92/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.6751 - mse: 16.6751 - val_loss: 60.4743 - val_mse: 60.4743\n",
      "Epoch 93/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6820 - mse: 16.6820 - val_loss: 60.4812 - val_mse: 60.4812\n",
      "Epoch 94/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6798 - mse: 16.6798 - val_loss: 60.5674 - val_mse: 60.5674\n",
      "Epoch 95/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6769 - mse: 16.6769 - val_loss: 60.5608 - val_mse: 60.5608\n",
      "Epoch 96/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6746 - mse: 16.6746 - val_loss: 60.4912 - val_mse: 60.4912\n",
      "Epoch 97/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6689 - mse: 16.6689 - val_loss: 60.3277 - val_mse: 60.3277\n",
      "Epoch 98/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6503 - mse: 16.6503 - val_loss: 60.2813 - val_mse: 60.2813\n",
      "Epoch 99/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6475 - mse: 16.6475 - val_loss: 60.2191 - val_mse: 60.2191\n",
      "Epoch 100/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6283 - mse: 16.6283 - val_loss: 60.0306 - val_mse: 60.0306\n",
      "Epoch 101/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6337 - mse: 16.6337 - val_loss: 59.8204 - val_mse: 59.8204\n",
      "Epoch 102/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6341 - mse: 16.6341 - val_loss: 59.6657 - val_mse: 59.6657\n",
      "Epoch 103/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6362 - mse: 16.6362 - val_loss: 59.6082 - val_mse: 59.6083\n",
      "Epoch 104/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.6615 - mse: 16.6615 - val_loss: 59.5444 - val_mse: 59.5444\n",
      "Epoch 105/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.6422 - mse: 16.6422 - val_loss: 59.7085 - val_mse: 59.7085\n",
      "Epoch 106/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6132 - mse: 16.6132 - val_loss: 59.8287 - val_mse: 59.8287\n",
      "Epoch 107/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6122 - mse: 16.6122 - val_loss: 59.9478 - val_mse: 59.9478\n",
      "Epoch 108/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.6039 - mse: 16.6039 - val_loss: 59.9396 - val_mse: 59.9396\n",
      "Epoch 109/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5996 - mse: 16.5996 - val_loss: 59.9667 - val_mse: 59.9667\n",
      "Epoch 110/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5908 - mse: 16.5908 - val_loss: 59.9040 - val_mse: 59.9040\n",
      "Epoch 111/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5884 - mse: 16.5884 - val_loss: 59.8504 - val_mse: 59.8504\n",
      "Epoch 112/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5913 - mse: 16.5913 - val_loss: 59.9046 - val_mse: 59.9046\n",
      "Epoch 113/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5800 - mse: 16.5800 - val_loss: 59.8231 - val_mse: 59.8231\n",
      "Epoch 114/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5746 - mse: 16.5746 - val_loss: 59.8530 - val_mse: 59.8530\n",
      "Epoch 115/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5677 - mse: 16.5677 - val_loss: 59.8831 - val_mse: 59.8831\n",
      "Epoch 116/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5622 - mse: 16.5622 - val_loss: 59.9703 - val_mse: 59.9703\n",
      "Epoch 117/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5588 - mse: 16.5588 - val_loss: 60.0322 - val_mse: 60.0322\n",
      "Epoch 118/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5653 - mse: 16.5653 - val_loss: 60.1108 - val_mse: 60.1108\n",
      "Epoch 119/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5635 - mse: 16.5635 - val_loss: 60.0524 - val_mse: 60.0524\n",
      "Epoch 120/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5521 - mse: 16.5521 - val_loss: 60.0546 - val_mse: 60.0546\n",
      "Epoch 121/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.5503 - mse: 16.5503 - val_loss: 60.1053 - val_mse: 60.1053\n",
      "Epoch 122/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.5483 - mse: 16.5483 - val_loss: 60.1122 - val_mse: 60.1122\n",
      "Epoch 123/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5499 - mse: 16.5499 - val_loss: 60.0054 - val_mse: 60.0054\n",
      "Epoch 124/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5373 - mse: 16.5373 - val_loss: 59.8329 - val_mse: 59.8329\n",
      "Epoch 125/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5310 - mse: 16.5310 - val_loss: 59.7275 - val_mse: 59.7275\n",
      "Epoch 126/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5323 - mse: 16.5323 - val_loss: 59.6548 - val_mse: 59.6548\n",
      "Epoch 127/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.5243 - mse: 16.5243 - val_loss: 59.7028 - val_mse: 59.7028\n",
      "Epoch 128/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.5213 - mse: 16.5213 - val_loss: 59.7282 - val_mse: 59.7282\n",
      "Epoch 129/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5157 - mse: 16.5157 - val_loss: 59.7619 - val_mse: 59.7619\n",
      "Epoch 130/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5182 - mse: 16.5182 - val_loss: 59.8210 - val_mse: 59.8210\n",
      "Epoch 131/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5051 - mse: 16.5051 - val_loss: 59.7435 - val_mse: 59.7435\n",
      "Epoch 132/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5017 - mse: 16.5017 - val_loss: 59.6328 - val_mse: 59.6328\n",
      "Epoch 133/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5294 - mse: 16.5294 - val_loss: 59.5158 - val_mse: 59.5158\n",
      "Epoch 134/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5040 - mse: 16.5040 - val_loss: 59.5867 - val_mse: 59.5867\n",
      "Epoch 135/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4982 - mse: 16.4982 - val_loss: 59.6667 - val_mse: 59.6667\n",
      "Epoch 136/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.5021 - mse: 16.5021 - val_loss: 59.8297 - val_mse: 59.8297\n",
      "Epoch 137/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4871 - mse: 16.4871 - val_loss: 59.8957 - val_mse: 59.8957\n",
      "Epoch 138/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4807 - mse: 16.4807 - val_loss: 59.9404 - val_mse: 59.9404\n",
      "Epoch 139/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4791 - mse: 16.4791 - val_loss: 60.0468 - val_mse: 60.0468\n",
      "Epoch 140/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4773 - mse: 16.4773 - val_loss: 60.1606 - val_mse: 60.1606\n",
      "Epoch 141/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4788 - mse: 16.4788 - val_loss: 60.2110 - val_mse: 60.2110\n",
      "Epoch 142/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4792 - mse: 16.4792 - val_loss: 60.2374 - val_mse: 60.2374\n",
      "Epoch 143/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4847 - mse: 16.4847 - val_loss: 60.2827 - val_mse: 60.2827\n",
      "Epoch 144/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4790 - mse: 16.4790 - val_loss: 60.1242 - val_mse: 60.1243\n",
      "Epoch 145/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4623 - mse: 16.4623 - val_loss: 60.0406 - val_mse: 60.0406\n",
      "Epoch 146/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4562 - mse: 16.4562 - val_loss: 59.9259 - val_mse: 59.9259\n",
      "Epoch 147/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4573 - mse: 16.4573 - val_loss: 59.7739 - val_mse: 59.7739\n",
      "Epoch 148/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4456 - mse: 16.4456 - val_loss: 59.7255 - val_mse: 59.7255\n",
      "Epoch 149/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4432 - mse: 16.4432 - val_loss: 59.7152 - val_mse: 59.7152\n",
      "Epoch 150/400\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 16.4421 - mse: 16.4421 - val_loss: 59.7195 - val_mse: 59.7195\n",
      "Epoch 151/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4405 - mse: 16.4405 - val_loss: 59.5715 - val_mse: 59.5715\n",
      "Epoch 152/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4302 - mse: 16.4302 - val_loss: 59.5154 - val_mse: 59.5154\n",
      "Epoch 153/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4356 - mse: 16.4356 - val_loss: 59.4162 - val_mse: 59.4162\n",
      "Epoch 154/400\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.4281 - mse: 16.4281 - val_loss: 59.4070 - val_mse: 59.4070\n",
      "Epoch 155/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4233 - mse: 16.4233 - val_loss: 59.4317 - val_mse: 59.4316\n",
      "Epoch 156/400\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.4268 - mse: 16.4268 - val_loss: 59.5896 - val_mse: 59.5896\n",
      "Epoch 157/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4255 - mse: 16.4255 - val_loss: 59.7728 - val_mse: 59.7728\n",
      "Epoch 158/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4165 - mse: 16.4165 - val_loss: 59.8197 - val_mse: 59.8197\n",
      "Epoch 159/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.4101 - mse: 16.4101 - val_loss: 59.8299 - val_mse: 59.8299\n",
      "Epoch 160/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4071 - mse: 16.4071 - val_loss: 59.9133 - val_mse: 59.9133\n",
      "Epoch 161/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4086 - mse: 16.4086 - val_loss: 59.9978 - val_mse: 59.9978\n",
      "Epoch 162/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4094 - mse: 16.4094 - val_loss: 60.0942 - val_mse: 60.0942\n",
      "Epoch 163/400\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 16.4125 - mse: 16.4125 - val_loss: 60.0504 - val_mse: 60.0504\n",
      "Epoch 164/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4061 - mse: 16.4061 - val_loss: 59.8169 - val_mse: 59.8169\n",
      "Epoch 165/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3894 - mse: 16.3894 - val_loss: 59.5360 - val_mse: 59.5360\n",
      "Epoch 166/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3927 - mse: 16.3927 - val_loss: 59.3727 - val_mse: 59.3727\n",
      "Epoch 167/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3990 - mse: 16.3990 - val_loss: 59.2168 - val_mse: 59.2168\n",
      "Epoch 168/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.4047 - mse: 16.4047 - val_loss: 59.2239 - val_mse: 59.2239\n",
      "Epoch 169/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.4070 - mse: 16.4070 - val_loss: 59.3495 - val_mse: 59.3495\n",
      "Epoch 170/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3844 - mse: 16.3845 - val_loss: 59.4282 - val_mse: 59.4282\n",
      "Epoch 171/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3744 - mse: 16.3744 - val_loss: 59.5593 - val_mse: 59.5593\n",
      "Epoch 172/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3687 - mse: 16.3687 - val_loss: 59.6379 - val_mse: 59.6379\n",
      "Epoch 173/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3669 - mse: 16.3669 - val_loss: 59.7421 - val_mse: 59.7421\n",
      "Epoch 174/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3685 - mse: 16.3685 - val_loss: 59.7846 - val_mse: 59.7846\n",
      "Epoch 175/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3757 - mse: 16.3757 - val_loss: 59.9510 - val_mse: 59.9510\n",
      "Epoch 176/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3875 - mse: 16.3875 - val_loss: 60.0880 - val_mse: 60.0880\n",
      "Epoch 177/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3819 - mse: 16.3819 - val_loss: 60.0407 - val_mse: 60.0407\n",
      "Epoch 178/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.3744 - mse: 16.3744 - val_loss: 59.9685 - val_mse: 59.9685\n",
      "Epoch 179/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3577 - mse: 16.3577 - val_loss: 59.8130 - val_mse: 59.8130\n",
      "Epoch 180/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3461 - mse: 16.3461 - val_loss: 59.5923 - val_mse: 59.5923\n",
      "Epoch 181/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3649 - mse: 16.3649 - val_loss: 59.3712 - val_mse: 59.3712\n",
      "Epoch 182/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3560 - mse: 16.3560 - val_loss: 59.2674 - val_mse: 59.2674\n",
      "Epoch 183/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3523 - mse: 16.3523 - val_loss: 59.2764 - val_mse: 59.2764\n",
      "Epoch 184/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3480 - mse: 16.3480 - val_loss: 59.3380 - val_mse: 59.3380\n",
      "Epoch 185/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.3447 - mse: 16.3447 - val_loss: 59.4006 - val_mse: 59.4006\n",
      "Epoch 186/400\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 16.3373 - mse: 16.3373 - val_loss: 59.4805 - val_mse: 59.4805\n",
      "Epoch 187/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3359 - mse: 16.3359 - val_loss: 59.5515 - val_mse: 59.5515\n",
      "Epoch 188/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3371 - mse: 16.3371 - val_loss: 59.5093 - val_mse: 59.5093\n",
      "Epoch 189/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3294 - mse: 16.3294 - val_loss: 59.4864 - val_mse: 59.4864\n",
      "Epoch 190/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3302 - mse: 16.3302 - val_loss: 59.4035 - val_mse: 59.4035\n",
      "Epoch 191/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3211 - mse: 16.3211 - val_loss: 59.2629 - val_mse: 59.2629\n",
      "Epoch 192/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3418 - mse: 16.3418 - val_loss: 59.1556 - val_mse: 59.1556\n",
      "Epoch 193/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3321 - mse: 16.3321 - val_loss: 59.0957 - val_mse: 59.0957\n",
      "Epoch 194/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3517 - mse: 16.3517 - val_loss: 59.0910 - val_mse: 59.0910\n",
      "Epoch 195/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3315 - mse: 16.3315 - val_loss: 59.2971 - val_mse: 59.2971\n",
      "Epoch 196/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3137 - mse: 16.3137 - val_loss: 59.4456 - val_mse: 59.4456\n",
      "Epoch 197/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3176 - mse: 16.3176 - val_loss: 59.5807 - val_mse: 59.5807\n",
      "Epoch 198/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3142 - mse: 16.3142 - val_loss: 59.6157 - val_mse: 59.6157\n",
      "Epoch 199/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3155 - mse: 16.3155 - val_loss: 59.5356 - val_mse: 59.5356\n",
      "Epoch 200/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3127 - mse: 16.3127 - val_loss: 59.4295 - val_mse: 59.4295\n",
      "Epoch 201/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3058 - mse: 16.3058 - val_loss: 59.3723 - val_mse: 59.3723\n",
      "Epoch 202/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3158 - mse: 16.3158 - val_loss: 59.3015 - val_mse: 59.3015\n",
      "Epoch 203/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3032 - mse: 16.3032 - val_loss: 59.3738 - val_mse: 59.3738\n",
      "Epoch 204/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3002 - mse: 16.3002 - val_loss: 59.4786 - val_mse: 59.4786\n",
      "Epoch 205/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.3252 - mse: 16.3252 - val_loss: 59.7868 - val_mse: 59.7868\n",
      "Epoch 206/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.3193 - mse: 16.3193 - val_loss: 59.8544 - val_mse: 59.8544\n",
      "Epoch 207/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2917 - mse: 16.2917 - val_loss: 59.6447 - val_mse: 59.6447\n",
      "Epoch 208/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2893 - mse: 16.2893 - val_loss: 59.5017 - val_mse: 59.5016\n",
      "Epoch 209/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2894 - mse: 16.2894 - val_loss: 59.4484 - val_mse: 59.4484\n",
      "Epoch 210/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2891 - mse: 16.2891 - val_loss: 59.3518 - val_mse: 59.3518\n",
      "Epoch 211/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2879 - mse: 16.2879 - val_loss: 59.2302 - val_mse: 59.2302\n",
      "Epoch 212/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2957 - mse: 16.2957 - val_loss: 59.1707 - val_mse: 59.1707\n",
      "Epoch 213/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2956 - mse: 16.2956 - val_loss: 59.1915 - val_mse: 59.1915\n",
      "Epoch 214/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2913 - mse: 16.2913 - val_loss: 59.2325 - val_mse: 59.2325\n",
      "Epoch 215/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2998 - mse: 16.2998 - val_loss: 59.3081 - val_mse: 59.3081\n",
      "Epoch 216/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2853 - mse: 16.2853 - val_loss: 59.2646 - val_mse: 59.2646\n",
      "Epoch 217/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2872 - mse: 16.2872 - val_loss: 59.3455 - val_mse: 59.3455\n",
      "Epoch 218/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2771 - mse: 16.2771 - val_loss: 59.3677 - val_mse: 59.3677\n",
      "Epoch 219/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2954 - mse: 16.2954 - val_loss: 59.5644 - val_mse: 59.5645\n",
      "Epoch 220/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2746 - mse: 16.2746 - val_loss: 59.5667 - val_mse: 59.5667\n",
      "Epoch 221/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2800 - mse: 16.2800 - val_loss: 59.4701 - val_mse: 59.4701\n",
      "Epoch 222/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2656 - mse: 16.2656 - val_loss: 59.5348 - val_mse: 59.5348\n",
      "Epoch 223/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2584 - mse: 16.2584 - val_loss: 59.6845 - val_mse: 59.6845\n",
      "Epoch 224/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.2643 - mse: 16.2643 - val_loss: 59.7944 - val_mse: 59.7944\n",
      "Epoch 225/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.2668 - mse: 16.2668 - val_loss: 59.8415 - val_mse: 59.8415\n",
      "Epoch 226/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2660 - mse: 16.2660 - val_loss: 59.7961 - val_mse: 59.7961\n",
      "Epoch 227/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2688 - mse: 16.2688 - val_loss: 59.6306 - val_mse: 59.6306\n",
      "Epoch 228/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2711 - mse: 16.2711 - val_loss: 59.5662 - val_mse: 59.5662\n",
      "Epoch 229/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2553 - mse: 16.2553 - val_loss: 59.6825 - val_mse: 59.6825\n",
      "Epoch 230/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2568 - mse: 16.2568 - val_loss: 59.7209 - val_mse: 59.7209\n",
      "Epoch 231/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2518 - mse: 16.2518 - val_loss: 59.8668 - val_mse: 59.8668\n",
      "Epoch 232/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.2650 - mse: 16.2650 - val_loss: 60.0763 - val_mse: 60.0763\n",
      "Epoch 233/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2681 - mse: 16.2681 - val_loss: 60.1265 - val_mse: 60.1265\n",
      "Epoch 234/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2650 - mse: 16.2650 - val_loss: 59.9935 - val_mse: 59.9935\n",
      "Epoch 235/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2728 - mse: 16.2728 - val_loss: 59.7955 - val_mse: 59.7955\n",
      "Epoch 236/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2501 - mse: 16.2501 - val_loss: 59.7498 - val_mse: 59.7497\n",
      "Epoch 237/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2495 - mse: 16.2495 - val_loss: 59.6145 - val_mse: 59.6145\n",
      "Epoch 238/400\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.2460 - mse: 16.2460 - val_loss: 59.5605 - val_mse: 59.5605\n",
      "Epoch 239/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2473 - mse: 16.2473 - val_loss: 59.4998 - val_mse: 59.4998\n",
      "Epoch 240/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2440 - mse: 16.2440 - val_loss: 59.6164 - val_mse: 59.6164\n",
      "Epoch 241/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2404 - mse: 16.2404 - val_loss: 59.5927 - val_mse: 59.5927\n",
      "Epoch 242/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2372 - mse: 16.2372 - val_loss: 59.5923 - val_mse: 59.5923\n",
      "Epoch 243/400\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.2331 - mse: 16.2331 - val_loss: 59.5019 - val_mse: 59.5019\n",
      "Epoch 244/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2304 - mse: 16.2304 - val_loss: 59.4758 - val_mse: 59.4758\n",
      "Epoch 245/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2366 - mse: 16.2366 - val_loss: 59.4037 - val_mse: 59.4037\n",
      "Epoch 246/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2370 - mse: 16.2370 - val_loss: 59.3632 - val_mse: 59.3632\n",
      "Epoch 247/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2609 - mse: 16.2609 - val_loss: 59.1738 - val_mse: 59.1738\n",
      "Epoch 248/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2396 - mse: 16.2396 - val_loss: 59.2420 - val_mse: 59.2420\n",
      "Epoch 249/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2502 - mse: 16.2502 - val_loss: 59.4174 - val_mse: 59.4174\n",
      "Epoch 250/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2227 - mse: 16.2227 - val_loss: 59.4854 - val_mse: 59.4854\n",
      "Epoch 251/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2271 - mse: 16.2271 - val_loss: 59.5259 - val_mse: 59.5259\n",
      "Epoch 252/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2152 - mse: 16.2152 - val_loss: 59.6634 - val_mse: 59.6634\n",
      "Epoch 253/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2192 - mse: 16.2192 - val_loss: 59.8124 - val_mse: 59.8124\n",
      "Epoch 254/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2163 - mse: 16.2163 - val_loss: 59.8237 - val_mse: 59.8237\n",
      "Epoch 255/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2137 - mse: 16.2137 - val_loss: 59.8602 - val_mse: 59.8603\n",
      "Epoch 256/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2140 - mse: 16.2140 - val_loss: 59.7944 - val_mse: 59.7944\n",
      "Epoch 257/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2099 - mse: 16.2099 - val_loss: 59.7247 - val_mse: 59.7247\n",
      "Epoch 258/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2054 - mse: 16.2054 - val_loss: 59.7070 - val_mse: 59.7070\n",
      "Epoch 259/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.2039 - mse: 16.2039 - val_loss: 59.6208 - val_mse: 59.6208\n",
      "Epoch 260/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2066 - mse: 16.2066 - val_loss: 59.5162 - val_mse: 59.5162\n",
      "Epoch 261/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2120 - mse: 16.2120 - val_loss: 59.2309 - val_mse: 59.2309\n",
      "Epoch 262/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2255 - mse: 16.2255 - val_loss: 59.0865 - val_mse: 59.0865\n",
      "Epoch 263/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2241 - mse: 16.2241 - val_loss: 59.1953 - val_mse: 59.1953\n",
      "Epoch 264/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2084 - mse: 16.2084 - val_loss: 59.2731 - val_mse: 59.2731\n",
      "Epoch 265/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2034 - mse: 16.2034 - val_loss: 59.3356 - val_mse: 59.3356\n",
      "Epoch 266/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1925 - mse: 16.1925 - val_loss: 59.5273 - val_mse: 59.5273\n",
      "Epoch 267/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1888 - mse: 16.1888 - val_loss: 59.7528 - val_mse: 59.7528\n",
      "Epoch 268/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1883 - mse: 16.1883 - val_loss: 59.8716 - val_mse: 59.8716\n",
      "Epoch 269/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2174 - mse: 16.2174 - val_loss: 60.0726 - val_mse: 60.0726\n",
      "Epoch 270/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2068 - mse: 16.2068 - val_loss: 60.0039 - val_mse: 60.0040\n",
      "Epoch 271/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2116 - mse: 16.2116 - val_loss: 59.8554 - val_mse: 59.8554\n",
      "Epoch 272/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.1908 - mse: 16.1908 - val_loss: 59.7947 - val_mse: 59.7947\n",
      "Epoch 273/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.1902 - mse: 16.1902 - val_loss: 59.6110 - val_mse: 59.6110\n",
      "Epoch 274/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1949 - mse: 16.1949 - val_loss: 59.4855 - val_mse: 59.4855\n",
      "Epoch 275/400\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 16.1812 - mse: 16.1812 - val_loss: 59.5273 - val_mse: 59.5273\n",
      "Epoch 276/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1831 - mse: 16.1831 - val_loss: 59.5209 - val_mse: 59.5209\n",
      "Epoch 277/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1821 - mse: 16.1821 - val_loss: 59.5888 - val_mse: 59.5888\n",
      "Epoch 278/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1772 - mse: 16.1772 - val_loss: 59.6439 - val_mse: 59.6439\n",
      "Epoch 279/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1813 - mse: 16.1813 - val_loss: 59.7175 - val_mse: 59.7175\n",
      "Epoch 280/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1771 - mse: 16.1771 - val_loss: 59.7632 - val_mse: 59.7632\n",
      "Epoch 281/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1944 - mse: 16.1944 - val_loss: 60.0090 - val_mse: 60.0090\n",
      "Epoch 282/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.2123 - mse: 16.2123 - val_loss: 60.1502 - val_mse: 60.1502\n",
      "Epoch 283/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1811 - mse: 16.1811 - val_loss: 59.9801 - val_mse: 59.9801\n",
      "Epoch 284/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1709 - mse: 16.1709 - val_loss: 59.7428 - val_mse: 59.7428\n",
      "Epoch 285/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1876 - mse: 16.1876 - val_loss: 59.4672 - val_mse: 59.4672\n",
      "Epoch 286/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1746 - mse: 16.1746 - val_loss: 59.3617 - val_mse: 59.3617\n",
      "Epoch 287/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1754 - mse: 16.1754 - val_loss: 59.2875 - val_mse: 59.2875\n",
      "Epoch 288/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1728 - mse: 16.1728 - val_loss: 59.2773 - val_mse: 59.2773\n",
      "Epoch 289/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1786 - mse: 16.1786 - val_loss: 59.2776 - val_mse: 59.2776\n",
      "Epoch 290/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1706 - mse: 16.1706 - val_loss: 59.4236 - val_mse: 59.4236\n",
      "Epoch 291/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1695 - mse: 16.1695 - val_loss: 59.5359 - val_mse: 59.5359\n",
      "Epoch 292/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1617 - mse: 16.1617 - val_loss: 59.5297 - val_mse: 59.5297\n",
      "Epoch 293/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1547 - mse: 16.1547 - val_loss: 59.4039 - val_mse: 59.4039\n",
      "Epoch 294/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1858 - mse: 16.1858 - val_loss: 59.1719 - val_mse: 59.1719\n",
      "Epoch 295/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1762 - mse: 16.1762 - val_loss: 59.1825 - val_mse: 59.1825\n",
      "Epoch 296/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.2257 - mse: 16.2257 - val_loss: 58.9881 - val_mse: 58.9881\n",
      "Epoch 297/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1783 - mse: 16.1783 - val_loss: 59.1505 - val_mse: 59.1505\n",
      "Epoch 298/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.2027 - mse: 16.2027 - val_loss: 59.4884 - val_mse: 59.4884\n",
      "Epoch 299/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1526 - mse: 16.1526 - val_loss: 59.5692 - val_mse: 59.5692\n",
      "Epoch 300/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1580 - mse: 16.1580 - val_loss: 59.6756 - val_mse: 59.6756\n",
      "Epoch 301/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1545 - mse: 16.1545 - val_loss: 59.6267 - val_mse: 59.6267\n",
      "Epoch 302/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1446 - mse: 16.1446 - val_loss: 59.7014 - val_mse: 59.7014\n",
      "Epoch 303/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1489 - mse: 16.1489 - val_loss: 59.7760 - val_mse: 59.7760\n",
      "Epoch 304/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1452 - mse: 16.1452 - val_loss: 59.7481 - val_mse: 59.7480\n",
      "Epoch 305/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1553 - mse: 16.1553 - val_loss: 59.6886 - val_mse: 59.6886\n",
      "Epoch 306/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1452 - mse: 16.1452 - val_loss: 59.7012 - val_mse: 59.7012\n",
      "Epoch 307/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1452 - mse: 16.1452 - val_loss: 59.6778 - val_mse: 59.6778\n",
      "Epoch 308/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1411 - mse: 16.1411 - val_loss: 59.7512 - val_mse: 59.7512\n",
      "Epoch 309/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1531 - mse: 16.1531 - val_loss: 59.7957 - val_mse: 59.7957\n",
      "Epoch 310/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1558 - mse: 16.1558 - val_loss: 59.6245 - val_mse: 59.6245\n",
      "Epoch 311/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1469 - mse: 16.1469 - val_loss: 59.6631 - val_mse: 59.6631\n",
      "Epoch 312/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1382 - mse: 16.1382 - val_loss: 59.9372 - val_mse: 59.9372\n",
      "Epoch 313/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1511 - mse: 16.1511 - val_loss: 60.1013 - val_mse: 60.1013\n",
      "Epoch 314/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1435 - mse: 16.1435 - val_loss: 60.0301 - val_mse: 60.0301\n",
      "Epoch 315/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1435 - mse: 16.1435 - val_loss: 59.9383 - val_mse: 59.9383\n",
      "Epoch 316/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1332 - mse: 16.1332 - val_loss: 59.8428 - val_mse: 59.8428\n",
      "Epoch 317/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1356 - mse: 16.1356 - val_loss: 59.6088 - val_mse: 59.6088\n",
      "Epoch 318/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1299 - mse: 16.1299 - val_loss: 59.4038 - val_mse: 59.4038\n",
      "Epoch 319/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1388 - mse: 16.1388 - val_loss: 59.2820 - val_mse: 59.2820\n",
      "Epoch 320/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1433 - mse: 16.1433 - val_loss: 59.2334 - val_mse: 59.2334\n",
      "Epoch 321/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1456 - mse: 16.1456 - val_loss: 59.1869 - val_mse: 59.1869\n",
      "Epoch 322/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1560 - mse: 16.1560 - val_loss: 59.1639 - val_mse: 59.1639\n",
      "Epoch 323/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1460 - mse: 16.1460 - val_loss: 59.3237 - val_mse: 59.3237\n",
      "Epoch 324/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1358 - mse: 16.1358 - val_loss: 59.4291 - val_mse: 59.4291\n",
      "Epoch 325/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1295 - mse: 16.1295 - val_loss: 59.5037 - val_mse: 59.5037\n",
      "Epoch 326/400\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 16.1353 - mse: 16.1353 - val_loss: 59.5848 - val_mse: 59.5848\n",
      "Epoch 327/400\n",
      "4/4 [==============================] - 0s 11ms/step - loss: 16.1372 - mse: 16.1372 - val_loss: 59.4666 - val_mse: 59.4666\n",
      "Epoch 328/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1278 - mse: 16.1278 - val_loss: 59.5672 - val_mse: 59.5672\n",
      "Epoch 329/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1234 - mse: 16.1234 - val_loss: 59.5007 - val_mse: 59.5007\n",
      "Epoch 330/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1231 - mse: 16.1231 - val_loss: 59.4448 - val_mse: 59.4448\n",
      "Epoch 331/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1286 - mse: 16.1286 - val_loss: 59.4829 - val_mse: 59.4829\n",
      "Epoch 332/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1359 - mse: 16.1359 - val_loss: 59.6553 - val_mse: 59.6553\n",
      "Epoch 333/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1131 - mse: 16.1131 - val_loss: 59.6050 - val_mse: 59.6050\n",
      "Epoch 334/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1453 - mse: 16.1453 - val_loss: 59.4329 - val_mse: 59.4329\n",
      "Epoch 335/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1174 - mse: 16.1174 - val_loss: 59.5229 - val_mse: 59.5229\n",
      "Epoch 336/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1171 - mse: 16.1171 - val_loss: 59.6162 - val_mse: 59.6162\n",
      "Epoch 337/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1091 - mse: 16.1091 - val_loss: 59.7034 - val_mse: 59.7034\n",
      "Epoch 338/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1065 - mse: 16.1065 - val_loss: 59.7177 - val_mse: 59.7177\n",
      "Epoch 339/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1066 - mse: 16.1066 - val_loss: 59.7503 - val_mse: 59.7503\n",
      "Epoch 340/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1080 - mse: 16.1080 - val_loss: 59.7258 - val_mse: 59.7258\n",
      "Epoch 341/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1066 - mse: 16.1066 - val_loss: 59.6624 - val_mse: 59.6624\n",
      "Epoch 342/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1126 - mse: 16.1126 - val_loss: 59.7094 - val_mse: 59.7094\n",
      "Epoch 343/400\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 16.1173 - mse: 16.1173 - val_loss: 59.5489 - val_mse: 59.5489\n",
      "Epoch 344/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1246 - mse: 16.1246 - val_loss: 59.5220 - val_mse: 59.5220\n",
      "Epoch 345/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1182 - mse: 16.1182 - val_loss: 59.6826 - val_mse: 59.6826\n",
      "Epoch 346/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1415 - mse: 16.1415 - val_loss: 59.5928 - val_mse: 59.5928\n",
      "Epoch 347/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1049 - mse: 16.1049 - val_loss: 59.8023 - val_mse: 59.8023\n",
      "Epoch 348/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0904 - mse: 16.0904 - val_loss: 60.0111 - val_mse: 60.0111\n",
      "Epoch 349/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.1035 - mse: 16.1035 - val_loss: 60.1688 - val_mse: 60.1688\n",
      "Epoch 350/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1083 - mse: 16.1083 - val_loss: 60.1900 - val_mse: 60.1900\n",
      "Epoch 351/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1024 - mse: 16.1024 - val_loss: 60.0540 - val_mse: 60.0540\n",
      "Epoch 352/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0937 - mse: 16.0937 - val_loss: 59.9021 - val_mse: 59.9021\n",
      "Epoch 353/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0883 - mse: 16.0883 - val_loss: 59.6872 - val_mse: 59.6872\n",
      "Epoch 354/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0913 - mse: 16.0913 - val_loss: 59.5533 - val_mse: 59.5533\n",
      "Epoch 355/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0959 - mse: 16.0959 - val_loss: 59.5122 - val_mse: 59.5122\n",
      "Epoch 356/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0984 - mse: 16.0984 - val_loss: 59.4482 - val_mse: 59.4482\n",
      "Epoch 357/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1022 - mse: 16.1022 - val_loss: 59.4125 - val_mse: 59.4125\n",
      "Epoch 358/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.1054 - mse: 16.1054 - val_loss: 59.4495 - val_mse: 59.4495\n",
      "Epoch 359/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0920 - mse: 16.0920 - val_loss: 59.6101 - val_mse: 59.6101\n",
      "Epoch 360/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0852 - mse: 16.0852 - val_loss: 59.7505 - val_mse: 59.7505\n",
      "Epoch 361/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0835 - mse: 16.0835 - val_loss: 59.9456 - val_mse: 59.9456\n",
      "Epoch 362/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0877 - mse: 16.0877 - val_loss: 60.1033 - val_mse: 60.1033\n",
      "Epoch 363/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0918 - mse: 16.0918 - val_loss: 60.1377 - val_mse: 60.1377\n",
      "Epoch 364/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0940 - mse: 16.0940 - val_loss: 60.1693 - val_mse: 60.1693\n",
      "Epoch 365/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0942 - mse: 16.0942 - val_loss: 60.1484 - val_mse: 60.1484\n",
      "Epoch 366/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0984 - mse: 16.0984 - val_loss: 60.1826 - val_mse: 60.1826\n",
      "Epoch 367/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0903 - mse: 16.0903 - val_loss: 60.1348 - val_mse: 60.1348\n",
      "Epoch 368/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0918 - mse: 16.0918 - val_loss: 60.1315 - val_mse: 60.1315\n",
      "Epoch 369/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0978 - mse: 16.0978 - val_loss: 59.9407 - val_mse: 59.9407\n",
      "Epoch 370/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0829 - mse: 16.0829 - val_loss: 59.9550 - val_mse: 59.9550\n",
      "Epoch 371/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0755 - mse: 16.0755 - val_loss: 59.8618 - val_mse: 59.8618\n",
      "Epoch 372/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0826 - mse: 16.0826 - val_loss: 59.8121 - val_mse: 59.8121\n",
      "Epoch 373/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0822 - mse: 16.0822 - val_loss: 59.8341 - val_mse: 59.8341\n",
      "Epoch 374/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0838 - mse: 16.0838 - val_loss: 59.9295 - val_mse: 59.9295\n",
      "Epoch 375/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0758 - mse: 16.0758 - val_loss: 59.8789 - val_mse: 59.8789\n",
      "Epoch 376/400\n",
      "4/4 [==============================] - 0s 10ms/step - loss: 16.0675 - mse: 16.0675 - val_loss: 59.7184 - val_mse: 59.7184\n",
      "Epoch 377/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0797 - mse: 16.0797 - val_loss: 59.5460 - val_mse: 59.5460\n",
      "Epoch 378/400\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 16.0859 - mse: 16.0858 - val_loss: 59.5433 - val_mse: 59.5433\n",
      "Epoch 379/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0799 - mse: 16.0799 - val_loss: 59.6499 - val_mse: 59.6499\n",
      "Epoch 380/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.1071 - mse: 16.1071 - val_loss: 59.8254 - val_mse: 59.8254\n",
      "Epoch 381/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0869 - mse: 16.0869 - val_loss: 59.7586 - val_mse: 59.7586\n",
      "Epoch 382/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0852 - mse: 16.0852 - val_loss: 59.8622 - val_mse: 59.8622\n",
      "Epoch 383/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0638 - mse: 16.0638 - val_loss: 59.7578 - val_mse: 59.7578\n",
      "Epoch 384/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0826 - mse: 16.0826 - val_loss: 59.5854 - val_mse: 59.5854\n",
      "Epoch 385/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0785 - mse: 16.0785 - val_loss: 59.6674 - val_mse: 59.6674\n",
      "Epoch 386/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0829 - mse: 16.0829 - val_loss: 59.8700 - val_mse: 59.8700\n",
      "Epoch 387/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0726 - mse: 16.0726 - val_loss: 59.9059 - val_mse: 59.9059\n",
      "Epoch 388/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0627 - mse: 16.0627 - val_loss: 59.7516 - val_mse: 59.7516\n",
      "Epoch 389/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0603 - mse: 16.0603 - val_loss: 59.6969 - val_mse: 59.6969\n",
      "Epoch 390/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0674 - mse: 16.0674 - val_loss: 59.6392 - val_mse: 59.6392\n",
      "Epoch 391/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0663 - mse: 16.0663 - val_loss: 59.6834 - val_mse: 59.6834\n",
      "Epoch 392/400\n",
      "4/4 [==============================] - 0s 9ms/step - loss: 16.0601 - mse: 16.0601 - val_loss: 59.7122 - val_mse: 59.7122\n",
      "Epoch 393/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0617 - mse: 16.0617 - val_loss: 59.8129 - val_mse: 59.8129\n",
      "Epoch 394/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0540 - mse: 16.0540 - val_loss: 59.9740 - val_mse: 59.9740\n",
      "Epoch 395/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0627 - mse: 16.0627 - val_loss: 60.1752 - val_mse: 60.1752\n",
      "Epoch 396/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0620 - mse: 16.0620 - val_loss: 60.1661 - val_mse: 60.1661\n",
      "Epoch 397/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0638 - mse: 16.0638 - val_loss: 60.1672 - val_mse: 60.1672\n",
      "Epoch 398/400\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 16.0754 - mse: 16.0754 - val_loss: 60.2054 - val_mse: 60.2054\n",
      "Epoch 399/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0854 - mse: 16.0854 - val_loss: 59.9158 - val_mse: 59.9158\n",
      "Epoch 400/400\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 16.0575 - mse: 16.0575 - val_loss: 59.9406 - val_mse: 59.9406\n"
     ]
    }
   ],
   "source": [
    "model_shallow = model.fit(X_train_scaled, y_train, validation_split=0.3, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 17.4066 - mse: 17.4066 - 15ms/epoch - 7ms/step\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000218DE0AE4C8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 5, 1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 5.007126 ],\n",
       "        [ 5.8333597],\n",
       "        [ 4.679219 ],\n",
       "        [ 6.259147 ],\n",
       "        [ 4.568589 ]],\n",
       "\n",
       "       [[16.24184  ],\n",
       "        [14.041265 ],\n",
       "        [ 9.727432 ],\n",
       "        [ 8.579732 ],\n",
       "        [10.41443  ]],\n",
       "\n",
       "       [[ 6.3503647],\n",
       "        [ 6.7845354],\n",
       "        [ 5.7635455],\n",
       "        [ 5.389523 ],\n",
       "        [ 5.468379 ]],\n",
       "\n",
       "       [[10.856031 ],\n",
       "        [13.139171 ],\n",
       "        [16.088268 ],\n",
       "        [13.665759 ],\n",
       "        [13.393655 ]],\n",
       "\n",
       "       [[ 5.200884 ],\n",
       "        [ 5.0527163],\n",
       "        [ 6.681947 ],\n",
       "        [ 7.337763 ],\n",
       "        [ 5.1569633]],\n",
       "\n",
       "       [[ 6.943101 ],\n",
       "        [ 6.557103 ],\n",
       "        [ 5.780925 ],\n",
       "        [ 6.352924 ],\n",
       "        [ 8.496882 ]],\n",
       "\n",
       "       [[ 6.80952  ],\n",
       "        [ 6.568929 ],\n",
       "        [ 6.104815 ],\n",
       "        [ 6.177959 ],\n",
       "        [ 4.0821276]],\n",
       "\n",
       "       [[15.491928 ],\n",
       "        [ 9.099268 ],\n",
       "        [17.500036 ],\n",
       "        [15.372403 ],\n",
       "        [13.18666  ]],\n",
       "\n",
       "       [[15.337645 ],\n",
       "        [13.824668 ],\n",
       "        [10.629412 ],\n",
       "        [13.8144245],\n",
       "        [12.624713 ]],\n",
       "\n",
       "       [[11.874625 ],\n",
       "        [13.118287 ],\n",
       "        [17.981928 ],\n",
       "        [13.413521 ],\n",
       "        [11.724202 ]],\n",
       "\n",
       "       [[ 7.0514536],\n",
       "        [ 7.0014772],\n",
       "        [ 6.650173 ],\n",
       "        [10.419837 ],\n",
       "        [11.993231 ]],\n",
       "\n",
       "       [[ 7.7279763],\n",
       "        [ 9.391526 ],\n",
       "        [ 7.529909 ],\n",
       "        [ 7.0132976],\n",
       "        [ 7.5629725]],\n",
       "\n",
       "       [[ 4.7573776],\n",
       "        [ 5.394307 ],\n",
       "        [ 5.630458 ],\n",
       "        [ 5.421897 ],\n",
       "        [ 8.308171 ]],\n",
       "\n",
       "       [[ 5.539728 ],\n",
       "        [ 5.5332594],\n",
       "        [ 5.4580317],\n",
       "        [ 6.5844564],\n",
       "        [ 5.690012 ]],\n",
       "\n",
       "       [[ 5.476714 ],\n",
       "        [ 3.9051247],\n",
       "        [ 5.634902 ],\n",
       "        [ 4.544133 ],\n",
       "        [ 4.295955 ]],\n",
       "\n",
       "       [[10.7639   ],\n",
       "        [ 9.539332 ],\n",
       "        [ 9.541696 ],\n",
       "        [12.209442 ],\n",
       "        [10.294406 ]],\n",
       "\n",
       "       [[14.316974 ],\n",
       "        [10.015492 ],\n",
       "        [13.047915 ],\n",
       "        [17.720543 ],\n",
       "        [16.954147 ]],\n",
       "\n",
       "       [[ 5.6090026],\n",
       "        [ 6.3759522],\n",
       "        [ 7.1706734],\n",
       "        [ 6.597829 ],\n",
       "        [ 3.8798838]],\n",
       "\n",
       "       [[ 5.9434404],\n",
       "        [ 4.699177 ],\n",
       "        [ 5.8550925],\n",
       "        [ 6.1350064],\n",
       "        [ 4.2059402]],\n",
       "\n",
       "       [[ 4.9030485],\n",
       "        [ 5.7162642],\n",
       "        [ 6.5724783],\n",
       "        [ 5.5325413],\n",
       "        [ 3.3637109]],\n",
       "\n",
       "       [[ 5.3580437],\n",
       "        [ 8.329751 ],\n",
       "        [ 6.1514244],\n",
       "        [ 4.041642 ],\n",
       "        [ 4.4837804]],\n",
       "\n",
       "       [[ 6.2554207],\n",
       "        [ 9.829147 ],\n",
       "        [ 6.8246927],\n",
       "        [ 9.221821 ],\n",
       "        [ 8.58072  ]],\n",
       "\n",
       "       [[10.784109 ],\n",
       "        [ 6.6393633],\n",
       "        [ 7.2280273],\n",
       "        [ 8.991286 ],\n",
       "        [ 8.940977 ]],\n",
       "\n",
       "       [[10.815473 ],\n",
       "        [ 7.82753  ],\n",
       "        [ 7.8762984],\n",
       "        [ 7.794327 ],\n",
       "        [ 9.28589  ]],\n",
       "\n",
       "       [[ 4.8971806],\n",
       "        [ 6.451032 ],\n",
       "        [ 7.046052 ],\n",
       "        [ 4.6299977],\n",
       "        [ 4.208618 ]],\n",
       "\n",
       "       [[10.051621 ],\n",
       "        [10.273463 ],\n",
       "        [10.8228   ],\n",
       "        [25.171663 ],\n",
       "        [17.2966   ]],\n",
       "\n",
       "       [[ 7.7636075],\n",
       "        [ 7.4845214],\n",
       "        [ 8.1648035],\n",
       "        [ 7.3012943],\n",
       "        [ 6.101772 ]],\n",
       "\n",
       "       [[11.946257 ],\n",
       "        [12.43467  ],\n",
       "        [13.5416565],\n",
       "        [13.181104 ],\n",
       "        [13.0417385]],\n",
       "\n",
       "       [[ 6.2321873],\n",
       "        [ 5.536607 ],\n",
       "        [ 5.5744705],\n",
       "        [ 6.0048056],\n",
       "        [ 4.8565063]],\n",
       "\n",
       "       [[10.856013 ],\n",
       "        [ 7.6022162],\n",
       "        [ 8.600333 ],\n",
       "        [ 7.9951487],\n",
       "        [ 9.46458  ]],\n",
       "\n",
       "       [[ 7.8908916],\n",
       "        [ 6.681843 ],\n",
       "        [ 6.80768  ],\n",
       "        [10.459992 ],\n",
       "        [ 8.971622 ]],\n",
       "\n",
       "       [[12.8268175],\n",
       "        [10.498355 ],\n",
       "        [ 9.583953 ],\n",
       "        [ 8.466697 ],\n",
       "        [10.1697855]],\n",
       "\n",
       "       [[ 7.3315625],\n",
       "        [ 7.414565 ],\n",
       "        [ 9.409207 ],\n",
       "        [ 6.8224263],\n",
       "        [ 8.973347 ]],\n",
       "\n",
       "       [[ 6.344602 ],\n",
       "        [ 8.75624  ],\n",
       "        [ 6.541012 ],\n",
       "        [ 7.7368155],\n",
       "        [ 6.083869 ]],\n",
       "\n",
       "       [[ 9.757895 ],\n",
       "        [ 8.931524 ],\n",
       "        [ 8.228457 ],\n",
       "        [ 7.412095 ],\n",
       "        [ 6.0850744]],\n",
       "\n",
       "       [[15.180867 ],\n",
       "        [11.599037 ],\n",
       "        [10.468778 ],\n",
       "        [ 9.173116 ],\n",
       "        [11.766795 ]],\n",
       "\n",
       "       [[ 9.544279 ],\n",
       "        [12.763194 ],\n",
       "        [10.80795  ],\n",
       "        [ 9.1028   ],\n",
       "        [ 8.237674 ]],\n",
       "\n",
       "       [[ 7.437342 ],\n",
       "        [ 7.1615853],\n",
       "        [ 7.4494658],\n",
       "        [ 9.033438 ],\n",
       "        [ 6.639972 ]],\n",
       "\n",
       "       [[ 5.4112024],\n",
       "        [ 6.5949492],\n",
       "        [ 6.026189 ],\n",
       "        [ 6.1983404],\n",
       "        [ 7.286784 ]],\n",
       "\n",
       "       [[12.114562 ],\n",
       "        [ 9.966495 ],\n",
       "        [10.760206 ],\n",
       "        [13.732897 ],\n",
       "        [11.865204 ]],\n",
       "\n",
       "       [[ 5.241613 ],\n",
       "        [ 5.4461775],\n",
       "        [ 4.1174   ],\n",
       "        [ 4.8262153],\n",
       "        [ 3.9443336]],\n",
       "\n",
       "       [[15.306815 ],\n",
       "        [16.309319 ],\n",
       "        [16.311426 ],\n",
       "        [13.678714 ],\n",
       "        [12.782599 ]],\n",
       "\n",
       "       [[ 7.4823456],\n",
       "        [ 6.976346 ],\n",
       "        [ 7.9933915],\n",
       "        [ 5.8141756],\n",
       "        [ 7.0487404]],\n",
       "\n",
       "       [[19.040216 ],\n",
       "        [14.721263 ],\n",
       "        [ 9.994225 ],\n",
       "        [10.68699  ],\n",
       "        [13.593882 ]],\n",
       "\n",
       "       [[ 6.7447615],\n",
       "        [ 6.2242985],\n",
       "        [ 7.7692084],\n",
       "        [ 7.0830936],\n",
       "        [ 6.549467 ]],\n",
       "\n",
       "       [[12.286996 ],\n",
       "        [ 8.11282  ],\n",
       "        [10.418611 ],\n",
       "        [ 9.728803 ],\n",
       "        [ 7.2833695]],\n",
       "\n",
       "       [[10.72236  ],\n",
       "        [ 7.6600065],\n",
       "        [ 8.1103945],\n",
       "        [10.011006 ],\n",
       "        [10.282887 ]],\n",
       "\n",
       "       [[12.999824 ],\n",
       "        [10.716514 ],\n",
       "        [ 8.54877  ],\n",
       "        [ 9.678668 ],\n",
       "        [ 8.061173 ]],\n",
       "\n",
       "       [[ 6.7939663],\n",
       "        [ 7.92107  ],\n",
       "        [ 6.5272474],\n",
       "        [ 7.5247765],\n",
       "        [ 7.5833406]],\n",
       "\n",
       "       [[ 9.876826 ],\n",
       "        [10.075883 ],\n",
       "        [ 9.571169 ],\n",
       "        [10.309358 ],\n",
       "        [10.448523 ]],\n",
       "\n",
       "       [[15.828729 ],\n",
       "        [10.484184 ],\n",
       "        [13.714328 ],\n",
       "        [11.495003 ],\n",
       "        [ 9.566627 ]],\n",
       "\n",
       "       [[10.226392 ],\n",
       "        [12.064824 ],\n",
       "        [ 8.936999 ],\n",
       "        [ 8.823689 ],\n",
       "        [ 7.804212 ]],\n",
       "\n",
       "       [[ 7.2412887],\n",
       "        [ 8.025068 ],\n",
       "        [11.930245 ],\n",
       "        [14.39106  ],\n",
       "        [10.138553 ]]], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_scaler = MinMaxScaler()\n",
    "y_scaler.fit(y_train.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = y_scaler.inverse_transform(predicted.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.24  ,  5.81  ,  2.75  , 16.6027,  3.23  ,  5.4001,  3.67  ,\n",
       "       24.95  , 18.31  , 13.87  , 18.5   ,  5.43  ,  3.2363,  1.92  ,\n",
       "        3.24  ,  6.99  , 14.23  ,  2.17  ,  2.38  ,  2.495 ,  1.27  ,\n",
       "        7.01  ,  8.0752,  4.42  ,  3.48  , 18.9   ,  5.265 , 13.82  ,\n",
       "        3.61  ,  6.27  ,  3.83  ,  7.47  ,  6.15  ,  2.47  ,  4.0625,\n",
       "        9.87  ,  4.5   ,  3.65  ,  5.49  , 11.04  ,  2.79  , 29.07  ,\n",
       "        9.45  , 15.08  ,  6.99  ,  3.43  ,  3.34  ,  8.21  ,  5.43  ,\n",
       "       12.45  , 11.76  ,  4.63  , 11.9   ])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "83e1771ce1f9df5de1670795847cb857ef6bf5f13021e3cce81b976772d7099f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
