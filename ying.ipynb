{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function accepts the column number for the features (X) and the target (y).\n",
    "It chunks the data up with a rolling window of X - window to predict y.\n",
    "It returns two numpy arrays of X and y.\n",
    "'''\n",
    "\n",
    "def window_data(df, window, feature_col_1, feature_col_2, target_col):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_1:feature_col_2]\n",
    "        target = df.iloc[(i + window), target_col]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4D LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, chunk_rows, feature_col_1, feature_col_2, target_col):\n",
    "    X_list = df.iloc[:,feature_col_1:feature_col_2].values.tolist()\n",
    "    X_chunks=[X_list[i:i + chunk_rows] for i in range(0, len(X_list), chunk_rows)]\n",
    "    X = [X_chunks[i:i+window] for i in range (len(X_chunks)-window)]\n",
    "    y_list=df.iloc[:,target_col].values.tolist()\n",
    "    y_chunks = [y_list[i + chunk_rows-1] for i in range(0, len(y_list), chunk_rows)]\n",
    "    y = [y_chunks[i+window] for i in range(len(y_chunks)-window)]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function splits X and y into training and testing sets, scales the data with MinMaxScaler and reshapes features data for the LSTM model .\n",
    "'''\n",
    "def data_splited_scaled(df, window, feature_col_1,feature_col_2, target_col):  \n",
    "    X, y = window_data(df, window, feature_col_1,feature_col_2, target_col)\n",
    "    # Use 70% of the data for training and the remainder for testing\n",
    "    split = int(0.7 * len(X))\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training feature data X_train\n",
    "    scaler.fit(X_train.ravel().reshape(-1,1))\n",
    "\n",
    "    # Scale the features training and testing sets\n",
    "    X_train_scaled= scaler.transform(X_train.ravel().reshape(-1,1))\n",
    "    X_test_scaled = scaler.transform(X_test.ravel().reshape(-1,1))\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training target data y_train\n",
    "    scaler.fit(y_train)\n",
    "\n",
    "    # Scale the target training and testing sets\n",
    "    y_train_scaled = scaler.transform(y_train)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    "    # Reshape the features for the model\n",
    "    feature_num = feature_col_2 - feature_col_1\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train.shape[0], X_train.shape[1], feature_num))\n",
    "    X_test_scaled = X_test_scaled.reshape((X_test.shape[0], X_test.shape[1], feature_num))\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function builds and trains a 3-layer LSTM model\n",
    "\n",
    "'''\n",
    "def lstm_model(df, window, feature_col_1, feature_col_2, target_col, number_units):\n",
    "\n",
    "    X_train_scaled, _, y_train_scaled, _ ,_= data_splited_scaled(df, window, feature_col_1,feature_col_2, target_col)\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    dropout_fraction = 0.2\n",
    "    # calculate\n",
    "    X_train_scaled, _, _, _ ,_= data_splited_scaled(df, window, feature_col_1, feature_col_2, target_col)\n",
    "    # Layer 1\n",
    "    feature_num = feature_col_2 - feature_col_1\n",
    "    lstm_model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_scaled.shape[1], feature_num))\n",
    "    )\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 2\n",
    "    lstm_model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 3\n",
    "    lstm_model.add(LSTM(units=number_units))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Output layer\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    # Compile the lstm_model\n",
    "    lstm_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the lstm_model\n",
    "    lstm_model.fit(X_train_scaled, y_train_scaled, epochs=10, shuffle=False, batch_size=1, verbose=1)\n",
    "\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function evaluates the LSTM model\n",
    "'''\n",
    "def lstm_evaluation(df, window, feature_col_1, feature_col_2, target_col, number_units):\n",
    "    _, X_test_scaled, _, y_test_scaled,_ =data_splited_scaled(df, window, feature_col_1, feature_col_2, target_col)\n",
    "    model = lstm_model(df, window, feature_col_1, feature_col_2, target_col, number_units)\n",
    "    score = model.evaluate(X_test_scaled, y_test_scaled,verbose=0)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function predicts y values and recover the original prices, and then creates a dataframe of Acural and Predicted values of y\n",
    "'''\n",
    "def lstm_prediction(df, window, feature_col_1, feature_col_2,target_col, number_units):\n",
    "    _, X_test_scaled, _, y_test_scaled,scaler =data_splited_scaled(df, window, feature_col_1,feature_col_2, target_col)\n",
    "    model= lstm_model(df, window, feature_col_1, feature_col_2, target_col, number_units)\n",
    "    y_predicted = model.predict(X_test_scaled)\n",
    "\n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = scaler.inverse_transform(y_predicted)\n",
    "    actual_prices = scaler.inverse_transform(y_test_scaled.reshape(-1, 1))\n",
    "\n",
    "    prediction_df = pd.DataFrame({\n",
    "        \"Actual\":actual_prices.ravel(),\n",
    "        \"Predicted\":predicted_prices.ravel(),\n",
    "    })\n",
    "\n",
    "    return prediction_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting Funtions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plotting(df, title):\n",
    "\n",
    "    '''\n",
    "    This function plots the history data.\n",
    "    '''\n",
    "\n",
    "    return df.hvplot(\n",
    "                    ylabel = 'Price in $',\n",
    "                    width= 1000,\n",
    "                    height=400,\n",
    "                    title=title)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avgs_plotting(df,ma_column_1, ma_column_2, title):\n",
    "    '''\n",
    "    This function plots the overlay of the original prices and moving averages.\n",
    "    '''\n",
    "    prices = df['close'].hvplot(line_color='lightgray',\n",
    "                        ylabel='Price in $',\n",
    "                        width=1000,\n",
    "                        height=400,\n",
    "                        title=title\n",
    "                        )\n",
    "\n",
    "    moving_avgs = df[[ma_column_1, ma_column_2]].hvplot(\n",
    "                            ylabel='Price in $',\n",
    "                            width=1000,\n",
    "                            height=400\n",
    "    )   \n",
    "\n",
    "    return prices*moving_avgs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_price_plotting(df,title):\n",
    "    '''\n",
    "    This function plots the actual prices vs. the predicted prices.\n",
    "    '''\n",
    "    return df[[\"actual\",\"predicted\"]].hvplot(\n",
    "                    ylabel='Price in $',\n",
    "                    width=1000,\n",
    "                    height=400,\n",
    "                    title=title\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bands_plotting(df, title ):\n",
    "    '''\n",
    "    This function plots the range of the prices.\n",
    "    '''\n",
    "    close = df['close'].hvplot(\n",
    "        line_color=\"lightgray\",\n",
    "        ylabel=\"Price in $\",\n",
    "        width=1000,\n",
    "        height=400,\n",
    "        title=title\n",
    "    )\n",
    "\n",
    "    upper_band = df['upper'].hvplot(\n",
    "        line_color=\"purple\",\n",
    "        ylabel = \"Price in $\",\n",
    "        width=1000,\n",
    "        height=400,\n",
    "    )\n",
    "\n",
    "    middle = df['middle'].hvplot(\n",
    "        line_color=\"orange\",\n",
    "        ylabel = \"Price in $\",\n",
    "        width = 1000,\n",
    "        height = 400\n",
    "    )\n",
    "\n",
    "\n",
    "    lower_band = df['lower'].hvplot(\n",
    "        line_color=\"blue\",\n",
    "        ylabel = \"Price in $\",\n",
    "        width = 1000,\n",
    "        height = 400\n",
    "    )\n",
    "\n",
    "    # Overlay plots\n",
    "    return close * upper_band *middle *lower_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_exit_positions(df, title):\n",
    "    '''\n",
    "    This function plots the entry/exit positions using ranges.\n",
    "    '''\n",
    "    entry = df[df[\"signal\"] == 1.0][\"close\"].hvplot.scatter(\n",
    "    color=\"green\",\n",
    "    marker=\"^\",\n",
    "    size=200,\n",
    "    legend=False,\n",
    "    ylabel=\"Price in $\",\n",
    "    title=title,\n",
    "    width=1000,\n",
    "    height=400,\n",
    ")\n",
    "\n",
    "# Visualize exit position relative to close price\n",
    "    exit = df[df[\"signal\"] == -1.0][\"close\"].hvplot.scatter(\n",
    "    color=\"red\",\n",
    "    marker=\"v\",\n",
    "    size=200,\n",
    "    legend=False,\n",
    "    ylabel=\"Price in $\",\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "# Visualize close price for the investment\n",
    "    close = df[[\"close\"]].hvplot(\n",
    "    line_color=\"lightgray\",\n",
    "    ylabel=\"Price in $\",\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "    upper = df[[\"upper\"]].hvplot(\n",
    "    line_color=\"purple\",\n",
    "    ylabel=\"Price in $\",\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "    middle = df[[\"middle\"]].hvplot(\n",
    "    line_color=\"orange\",\n",
    "    ylabel=\"Price in $\",\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "    lower = df[[\"Lower\"]].hvplot(\n",
    "    line_color=\"blue\",\n",
    "    ylabel=\"Price in $\",\n",
    "    width=1000,\n",
    "    height=400\n",
    ")\n",
    "\n",
    "\n",
    "# Overlay plots\n",
    "    return close * upper * middle * lower * entry * exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eda12c2122dd4de2a2eea024d65cac832728e3fb16b3b5d201b2f43f2d409343"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pyvizenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
