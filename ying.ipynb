{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function accepts the column number for the features (X) and the target (y).\n",
    "It chunks the data up with a rolling window of Xt - window to predict Xt.\n",
    "It returns two numpy arrays of X and y.\n",
    "'''\n",
    "\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function splits X and y into training and testing sets, scales the data with MinMaxScaler and reshapes features data for the LSTM model .\n",
    "'''\n",
    "def data_splited_scaled(df, window, feature_column, target_column):  \n",
    "    X, y = window_data(df, window, feature_column, target_column)\n",
    "    # Use 70% of the data for training and the remainder for testing\n",
    "    split = int(0.7 * len(X))\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    # Use the MinMaxScaler to scale data between 0 and 1.\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training feature data X_train\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    # Scale the features training and testing sets\n",
    "    X_train_scaled= scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training target data y_train\n",
    "    scaler.fit(y_train)\n",
    "\n",
    "    # Scale the target training and testing sets\n",
    "    y_train_scaled = scaler.transform(y_train)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    "    # Reshape the features for the model\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "    X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function builds and trains a 3-layer LSTM model\n",
    "\n",
    "'''\n",
    "def lstm_model(df, window, feature_column, target_column, number_units):\n",
    "\n",
    "    X_train_scaled, _, y_train_scaled, _ ,_= data_splited_scaled(df, window, feature_column, target_column)\n",
    "\n",
    "    # Import required Keras modules\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    dropout_fraction = 0.2\n",
    "    # calculate\n",
    "    X_train_scaled, _, _, _ ,_= data_splited_scaled(df, window, feature_column, target_column)\n",
    "    # Layer 1\n",
    "    lstm_model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_scaled.shape[1], 1))\n",
    "    )\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 2\n",
    "    lstm_model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 3\n",
    "    lstm_model.add(LSTM(units=number_units))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Output layer\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    # Compile the lstm_model\n",
    "    lstm_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the lstm_model\n",
    "    lstm_model.fit(X_train_scaled, y_train_scaled, epochs=10, shuffle=False, batch_size=1, verbose=1)\n",
    "\n",
    "    return lstm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function evaluates the LSTM model\n",
    "'''\n",
    "def lstm_evaluation(df, window, feature_column, target_column, number_units):\n",
    "    _, X_test_scaled, _, y_test_scaled,_ =data_splited_scaled(df, window, feature_column, target_column)\n",
    "    model = lstm_model(df, window, feature_column, target_column, number_units)\n",
    "    score = model.evaluate(X_test_scaled, y_test_scaled,verbose=0)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function predicts y values and recover the original prices, and then creates a dataframe of Acural and Predicted values of y\n",
    "'''\n",
    "def lstm_prediction(df, window, feature_column, target_column, number_units):\n",
    "    _, X_test_scaled, _, y_test_scaled,scaler =data_splited_scaled(df, window, feature_column, target_column)\n",
    "    model= lstm_model(df, window, feature_column, target_column, number_units)\n",
    "    y_predicted = model.predict(X_test_scaled)\n",
    "\n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = scaler.inverse_transform(y_predicted)\n",
    "    actual_prices = scaler.inverse_transform(y_test_scaled.reshape(-1, 1))\n",
    "\n",
    "    prediction_df = pd.DataFrame({\n",
    "        \"Actual\":actual_prices.ravel(),\n",
    "        \"Predicted\":predicted_prices.ravel(),\n",
    "    })\n",
    "\n",
    "    return prediction_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b020d37e2d2792244d38dc749b48635155a26318d10fe99dbb63be9f4ff243c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
