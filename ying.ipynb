{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Dropout, Flatten\n",
    "import hvplot.pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for creating dataframe\n",
    "from utils_laramie import get_df, get_all_raw_data\n",
    "\n",
    "# imports for getting weekly range\n",
    "from utils_laramie import calc_weekly_range\n",
    "\n",
    "#imports for grouping data into weekly windows\n",
    "from utils_laramie import grp_y_wk_d, drop_off_weeks\n",
    "\n",
    "#shape data\n",
    "from utils_laramie import get_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY_open</th>\n",
       "      <th>SPY_high</th>\n",
       "      <th>SPY_low</th>\n",
       "      <th>SPY_close</th>\n",
       "      <th>SPY_volume</th>\n",
       "      <th>SPY_trade_count</th>\n",
       "      <th>SPY_vwap</th>\n",
       "      <th>TR</th>\n",
       "      <th>VIX_open</th>\n",
       "      <th>VIX_high</th>\n",
       "      <th>VIX_low</th>\n",
       "      <th>VIX_close</th>\n",
       "      <th>weekly_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1045</th>\n",
       "      <td>431.58</td>\n",
       "      <td>432.3018</td>\n",
       "      <td>419.36</td>\n",
       "      <td>419.43</td>\n",
       "      <td>131262026.0</td>\n",
       "      <td>1390460.0</td>\n",
       "      <td>424.067609</td>\n",
       "      <td>12.9418</td>\n",
       "      <td>35.88</td>\n",
       "      <td>36.55</td>\n",
       "      <td>32.59</td>\n",
       "      <td>36.45</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1046</th>\n",
       "      <td>419.87</td>\n",
       "      <td>427.2100</td>\n",
       "      <td>415.12</td>\n",
       "      <td>416.25</td>\n",
       "      <td>158890009.0</td>\n",
       "      <td>1864071.0</td>\n",
       "      <td>419.755053</td>\n",
       "      <td>12.0900</td>\n",
       "      <td>36.19</td>\n",
       "      <td>37.52</td>\n",
       "      <td>32.78</td>\n",
       "      <td>35.13</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>425.16</td>\n",
       "      <td>429.5100</td>\n",
       "      <td>422.83</td>\n",
       "      <td>427.33</td>\n",
       "      <td>110176608.0</td>\n",
       "      <td>1079760.0</td>\n",
       "      <td>426.138376</td>\n",
       "      <td>13.2600</td>\n",
       "      <td>33.74</td>\n",
       "      <td>34.12</td>\n",
       "      <td>31.39</td>\n",
       "      <td>32.45</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>422.42</td>\n",
       "      <td>426.4300</td>\n",
       "      <td>420.44</td>\n",
       "      <td>425.48</td>\n",
       "      <td>91933914.0</td>\n",
       "      <td>891241.0</td>\n",
       "      <td>423.871044</td>\n",
       "      <td>6.8900</td>\n",
       "      <td>33.03</td>\n",
       "      <td>34.03</td>\n",
       "      <td>30.23</td>\n",
       "      <td>30.23</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1049</th>\n",
       "      <td>428.20</td>\n",
       "      <td>428.7700</td>\n",
       "      <td>419.53</td>\n",
       "      <td>420.07</td>\n",
       "      <td>90803923.0</td>\n",
       "      <td>809145.0</td>\n",
       "      <td>424.040193</td>\n",
       "      <td>9.2400</td>\n",
       "      <td>30.43</td>\n",
       "      <td>31.04</td>\n",
       "      <td>28.84</td>\n",
       "      <td>30.75</td>\n",
       "      <td>17.1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>420.98</td>\n",
       "      <td>424.5500</td>\n",
       "      <td>415.79</td>\n",
       "      <td>417.00</td>\n",
       "      <td>91251505.0</td>\n",
       "      <td>858504.0</td>\n",
       "      <td>419.220077</td>\n",
       "      <td>8.7600</td>\n",
       "      <td>31.03</td>\n",
       "      <td>33.18</td>\n",
       "      <td>30.06</td>\n",
       "      <td>31.77</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>419.66</td>\n",
       "      <td>426.8400</td>\n",
       "      <td>418.42</td>\n",
       "      <td>426.17</td>\n",
       "      <td>104219651.0</td>\n",
       "      <td>920659.0</td>\n",
       "      <td>422.752423</td>\n",
       "      <td>9.8400</td>\n",
       "      <td>33.13</td>\n",
       "      <td>33.83</td>\n",
       "      <td>29.57</td>\n",
       "      <td>29.83</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>429.94</td>\n",
       "      <td>435.6800</td>\n",
       "      <td>424.80</td>\n",
       "      <td>435.55</td>\n",
       "      <td>138130298.0</td>\n",
       "      <td>1344164.0</td>\n",
       "      <td>431.339744</td>\n",
       "      <td>10.8800</td>\n",
       "      <td>29.02</td>\n",
       "      <td>29.80</td>\n",
       "      <td>26.29</td>\n",
       "      <td>26.67</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>433.70</td>\n",
       "      <td>441.0700</td>\n",
       "      <td>433.19</td>\n",
       "      <td>441.07</td>\n",
       "      <td>100157174.0</td>\n",
       "      <td>784018.0</td>\n",
       "      <td>437.706981</td>\n",
       "      <td>7.8800</td>\n",
       "      <td>26.51</td>\n",
       "      <td>27.47</td>\n",
       "      <td>25.25</td>\n",
       "      <td>25.67</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>437.81</td>\n",
       "      <td>444.8600</td>\n",
       "      <td>437.22</td>\n",
       "      <td>444.31</td>\n",
       "      <td>102327793.0</td>\n",
       "      <td>790235.0</td>\n",
       "      <td>441.458916</td>\n",
       "      <td>7.6400</td>\n",
       "      <td>26.36</td>\n",
       "      <td>26.82</td>\n",
       "      <td>23.85</td>\n",
       "      <td>23.87</td>\n",
       "      <td>29.0700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SPY_open  SPY_high  SPY_low  SPY_close   SPY_volume  SPY_trade_count  \\\n",
       "1045    431.58  432.3018   419.36     419.43  131262026.0        1390460.0   \n",
       "1046    419.87  427.2100   415.12     416.25  158890009.0        1864071.0   \n",
       "1047    425.16  429.5100   422.83     427.33  110176608.0        1079760.0   \n",
       "1048    422.42  426.4300   420.44     425.48   91933914.0         891241.0   \n",
       "1049    428.20  428.7700   419.53     420.07   90803923.0         809145.0   \n",
       "1050    420.98  424.5500   415.79     417.00   91251505.0         858504.0   \n",
       "1051    419.66  426.8400   418.42     426.17  104219651.0         920659.0   \n",
       "1052    429.94  435.6800   424.80     435.55  138130298.0        1344164.0   \n",
       "1053    433.70  441.0700   433.19     441.07  100157174.0         784018.0   \n",
       "1054    437.81  444.8600   437.22     444.31  102327793.0         790235.0   \n",
       "\n",
       "        SPY_vwap       TR  VIX_open  VIX_high  VIX_low  VIX_close  \\\n",
       "1045  424.067609  12.9418     35.88     36.55    32.59      36.45   \n",
       "1046  419.755053  12.0900     36.19     37.52    32.78      35.13   \n",
       "1047  426.138376  13.2600     33.74     34.12    31.39      32.45   \n",
       "1048  423.871044   6.8900     33.03     34.03    30.23      30.23   \n",
       "1049  424.040193   9.2400     30.43     31.04    28.84      30.75   \n",
       "1050  419.220077   8.7600     31.03     33.18    30.06      31.77   \n",
       "1051  422.752423   9.8400     33.13     33.83    29.57      29.83   \n",
       "1052  431.339744  10.8800     29.02     29.80    26.29      26.67   \n",
       "1053  437.706981   7.8800     26.51     27.47    25.25      25.67   \n",
       "1054  441.458916   7.6400     26.36     26.82    23.85      23.87   \n",
       "\n",
       "      weekly_range  \n",
       "1045        0.0000  \n",
       "1046        0.0000  \n",
       "1047        0.0000  \n",
       "1048        0.0000  \n",
       "1049       17.1818  \n",
       "1050        0.0000  \n",
       "1051        0.0000  \n",
       "1052        0.0000  \n",
       "1053        0.0000  \n",
       "1054       29.0700  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the cleaned data \n",
    "\n",
    "df = (get_df(get_all_raw_data()))\n",
    "df = calc_weekly_range(df)\n",
    "df = grp_y_wk_d(df)\n",
    "df = drop_off_weeks(df)\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3D LSTM Functions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set the random seed for reproducibility\n",
    "# # Note: This is used for model prototyping, but it is good practice to comment this out and run multiple experiments to evaluate your model.\n",
    "# from numpy.random import seed\n",
    "\n",
    "# seed(1)\n",
    "# from tensorflow import random\n",
    "\n",
    "# random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_1, feature_col_2, target_col):\n",
    "    '''\n",
    "    This function accepts the column number for the features (X) and the target (y).\n",
    "    It chunks the data up with a rolling window of X(t )- window to predict y(t).\n",
    "    It returns two numpy arrays of X and y.\n",
    "    '''\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_1:feature_col_2]\n",
    "        target = df.iloc[(i + window), target_col]\n",
    "        y.append(target)\n",
    "        X.append(features)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[2.10600000e+02 2.11000000e+02 2.08230000e+02 2.08540000e+02\n",
      "   1.08069059e+08 3.67013000e+05 2.09563055e+02]\n",
      "  [2.08900000e+02 2.09150000e+02 2.04751100e+02 2.05580000e+02\n",
      "   1.66224154e+08 5.46768000e+05 2.06878936e+02]\n",
      "  [2.06100000e+02 2.09970000e+02 2.05930000e+02 2.09660000e+02\n",
      "   1.92878747e+08 5.56731000e+05 2.08178631e+02]\n",
      "  [2.09200000e+02 2.09729500e+02 2.07200000e+02 2.08270000e+02\n",
      "   1.02027111e+08 3.74705000e+05 2.08276128e+02]\n",
      "  [2.06480000e+02 2.08289000e+02 2.05780000e+02 2.06990000e+02\n",
      "   1.03372367e+08 3.87782000e+05 2.06966276e+02]]\n",
      "\n",
      " [[2.08900000e+02 2.09150000e+02 2.04751100e+02 2.05580000e+02\n",
      "   1.66224154e+08 5.46768000e+05 2.06878936e+02]\n",
      "  [2.06100000e+02 2.09970000e+02 2.05930000e+02 2.09660000e+02\n",
      "   1.92878747e+08 5.56731000e+05 2.08178631e+02]\n",
      "  [2.09200000e+02 2.09729500e+02 2.07200000e+02 2.08270000e+02\n",
      "   1.02027111e+08 3.74705000e+05 2.08276128e+02]\n",
      "  [2.06480000e+02 2.08289000e+02 2.05780000e+02 2.06990000e+02\n",
      "   1.03372367e+08 3.87782000e+05 2.06966276e+02]\n",
      "  [2.06200000e+02 2.08680000e+02 2.04180000e+02 2.05330000e+02\n",
      "   1.62401537e+08 5.86210000e+05 2.06034646e+02]]\n",
      "\n",
      " [[2.06100000e+02 2.09970000e+02 2.05930000e+02 2.09660000e+02\n",
      "   1.92878747e+08 5.56731000e+05 2.08178631e+02]\n",
      "  [2.09200000e+02 2.09729500e+02 2.07200000e+02 2.08270000e+02\n",
      "   1.02027111e+08 3.74705000e+05 2.08276128e+02]\n",
      "  [2.06480000e+02 2.08289000e+02 2.05780000e+02 2.06990000e+02\n",
      "   1.03372367e+08 3.87782000e+05 2.06966276e+02]\n",
      "  [2.06200000e+02 2.08680000e+02 2.04180000e+02 2.05330000e+02\n",
      "   1.62401537e+08 5.86210000e+05 2.06034646e+02]\n",
      "  [2.05440000e+02 2.07430000e+02 2.05140000e+02 2.05860000e+02\n",
      "   1.16128858e+08 4.04992000e+05 2.06102975e+02]]\n",
      "\n",
      " [[2.09200000e+02 2.09729500e+02 2.07200000e+02 2.08270000e+02\n",
      "   1.02027111e+08 3.74705000e+05 2.08276128e+02]\n",
      "  [2.06480000e+02 2.08289000e+02 2.05780000e+02 2.06990000e+02\n",
      "   1.03372367e+08 3.87782000e+05 2.06966276e+02]\n",
      "  [2.06200000e+02 2.08680000e+02 2.04180000e+02 2.05330000e+02\n",
      "   1.62401537e+08 5.86210000e+05 2.06034646e+02]\n",
      "  [2.05440000e+02 2.07430000e+02 2.05140000e+02 2.05860000e+02\n",
      "   1.16128858e+08 4.04992000e+05 2.06102975e+02]\n",
      "  [2.03380000e+02 2.04140000e+02 2.01510000e+02 2.01880000e+02\n",
      "   2.11173305e+08 6.69924000e+05 2.03150102e+02]]\n",
      "\n",
      " [[2.06480000e+02 2.08289000e+02 2.05780000e+02 2.06990000e+02\n",
      "   1.03372367e+08 3.87782000e+05 2.06966276e+02]\n",
      "  [2.06200000e+02 2.08680000e+02 2.04180000e+02 2.05330000e+02\n",
      "   1.62401537e+08 5.86210000e+05 2.06034646e+02]\n",
      "  [2.05440000e+02 2.07430000e+02 2.05140000e+02 2.05860000e+02\n",
      "   1.16128858e+08 4.04992000e+05 2.06102975e+02]\n",
      "  [2.03380000e+02 2.04140000e+02 2.01510000e+02 2.01880000e+02\n",
      "   2.11173305e+08 6.69924000e+05 2.03150102e+02]\n",
      "  [2.02100000e+02 2.03050000e+02 1.99950000e+02 2.03000000e+02\n",
      "   1.82357840e+08 7.26916000e+05 2.01724387e+02]]]\n",
      "[[5.88]\n",
      " [6.7 ]\n",
      " [4.55]\n",
      " [5.85]\n",
      " [6.23]]\n"
     ]
    }
   ],
   "source": [
    "X,y = window_data(df,5,0,7,7)\n",
    "print(X[0:5])\n",
    "print(y[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_splited_scaled(df, window, feature_col_1,feature_col_2, target_col):\n",
    "    '''\n",
    "    This function splits X and y into training and testing sets, scales the data with MinMaxScaler and reshapes features data for the 3 dimentional LSTM model .\n",
    "    '''  \n",
    "    X, y = window_data(df, window, feature_col_1,feature_col_2, target_col)\n",
    "    # Use 70% of the data for training and the remainder for testing\n",
    "    split = int(0.7 * len(X))\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training feature data X_train\n",
    "    scaler.fit(X_train.ravel().reshape(-1,1))\n",
    "\n",
    "    # Scale the features training and testing sets\n",
    "    X_train_scaled= scaler.transform(X_train.ravel().reshape(-1,1))\n",
    "    X_test_scaled = scaler.transform(X_test.ravel().reshape(-1,1))\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training target data y_train\n",
    "    scaler.fit(y_train)\n",
    "\n",
    "    # Scale the target training and testing sets\n",
    "    y_train_scaled = scaler.transform(y_train)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    "    # Reshape the features for the model\n",
    "    feature_num = feature_col_2 - feature_col_1\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train.shape[0], X_train.shape[1], feature_num))\n",
    "    X_test_scaled = X_test_scaled.reshape((X_test.shape[0], X_test.shape[1], feature_num))\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1110, 5, 7)\n",
      "(477, 5, 7)\n",
      "(1110, 1)\n",
      "(477, 1)\n",
      "[[[7.50044037e-08 7.60186620e-08 6.89949230e-08 6.97809732e-08\n",
      "   2.74024400e-01 9.30155981e-04 7.23750784e-08]\n",
      "  [7.06938057e-08 7.13277172e-08 6.01736648e-08 6.22754616e-08\n",
      "   4.21485124e-01 1.38595100e-03 6.55691032e-08]\n",
      "  [6.35939974e-08 7.34069468e-08 6.31629376e-08 7.26208966e-08\n",
      "   4.89071732e-01 1.41121364e-03 6.88646695e-08]\n",
      "  [7.14544995e-08 7.27971240e-08 6.63832078e-08 6.90963489e-08\n",
      "   2.58704160e-01 9.49660168e-04 6.91118873e-08]\n",
      "  [6.45575428e-08 6.91445261e-08 6.27825908e-08 6.58507222e-08\n",
      "   2.62115252e-01 9.82818809e-04 6.57905666e-08]]\n",
      "\n",
      " [[7.06938057e-08 7.13277172e-08 6.01736648e-08 6.22754616e-08\n",
      "   4.21485124e-01 1.38595100e-03 6.55691032e-08]\n",
      "  [6.35939974e-08 7.34069468e-08 6.31629376e-08 7.26208966e-08\n",
      "   4.89071732e-01 1.41121364e-03 6.88646695e-08]\n",
      "  [7.14544995e-08 7.27971240e-08 6.63832078e-08 6.90963489e-08\n",
      "   2.58704160e-01 9.49660168e-04 6.91118873e-08]\n",
      "  [6.45575428e-08 6.91445261e-08 6.27825908e-08 6.58507222e-08\n",
      "   2.62115252e-01 9.82818809e-04 6.57905666e-08]\n",
      "  [6.38475620e-08 7.01359637e-08 5.87255574e-08 6.16415501e-08\n",
      "   4.11792321e-01 1.48596194e-03 6.34282828e-08]]\n",
      "\n",
      " [[6.35939974e-08 7.34069468e-08 6.31629376e-08 7.26208966e-08\n",
      "   4.89071732e-01 1.41121364e-03 6.88646695e-08]\n",
      "  [7.14544995e-08 7.27971240e-08 6.63832078e-08 6.90963489e-08\n",
      "   2.58704160e-01 9.49660168e-04 6.91118873e-08]\n",
      "  [6.45575428e-08 6.91445261e-08 6.27825908e-08 6.58507222e-08\n",
      "   2.62115252e-01 9.82818809e-04 6.57905666e-08]\n",
      "  [6.38475620e-08 7.01359637e-08 5.87255574e-08 6.16415501e-08\n",
      "   4.11792321e-01 1.48596194e-03 6.34282828e-08]\n",
      "  [6.19204712e-08 6.69664064e-08 6.11597774e-08 6.29854424e-08\n",
      "   2.94461196e-01 1.02645727e-03 6.36015410e-08]]\n",
      "\n",
      " [[7.14544995e-08 7.27971240e-08 6.63832078e-08 6.90963489e-08\n",
      "   2.58704160e-01 9.49660168e-04 6.91118873e-08]\n",
      "  [6.45575428e-08 6.91445261e-08 6.27825908e-08 6.58507222e-08\n",
      "   2.62115252e-01 9.82818809e-04 6.57905666e-08]\n",
      "  [6.38475620e-08 7.01359637e-08 5.87255574e-08 6.16415501e-08\n",
      "   4.11792321e-01 1.48596194e-03 6.34282828e-08]\n",
      "  [6.19204712e-08 6.69664064e-08 6.11597774e-08 6.29854424e-08\n",
      "   2.94461196e-01 1.02645727e-03 6.36015410e-08]\n",
      "  [5.66970408e-08 5.86241316e-08 5.19553831e-08 5.28935720e-08\n",
      "   5.35460251e-01 1.69823099e-03 5.61141009e-08]]\n",
      "\n",
      " [[6.45575428e-08 6.91445261e-08 6.27825908e-08 6.58507222e-08\n",
      "   2.62115252e-01 9.82818809e-04 6.57905666e-08]\n",
      "  [6.38475620e-08 7.01359637e-08 5.87255574e-08 6.16415501e-08\n",
      "   4.11792321e-01 1.48596194e-03 6.34282828e-08]\n",
      "  [6.19204712e-08 6.69664064e-08 6.11597774e-08 6.29854424e-08\n",
      "   2.94461196e-01 1.02645727e-03 6.36015410e-08]\n",
      "  [5.66970408e-08 5.86241316e-08 5.19553831e-08 5.28935720e-08\n",
      "   5.35460251e-01 1.69823099e-03 5.61141009e-08]\n",
      "  [5.34514141e-08 5.58602776e-08 4.79997756e-08 5.57334953e-08\n",
      "   4.62394438e-01 1.84274252e-03 5.24989926e-08]]]\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler = data_splited_scaled(df,5,0,7,7)\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(y_train_scaled.shape)\n",
    "print(y_test_scaled.shape)\n",
    "print(X_train_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model(df, window, feature_col_1, feature_col_2, target_col, number_units):\n",
    "    '''\n",
    "    This function builds and trains a 3-layer LSTM model to fit the 3 dimentional data.\n",
    "    '''\n",
    "    X_train_scaled, _, y_train_scaled, _ ,_= data_splited_scaled(df, window,feature_col_1, feature_col_2, target_col)\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    dropout_fraction = 0.2\n",
    "    # calculate\n",
    "    X_train_scaled, _, _, _ ,_= data_splited_scaled(df, window,feature_col_1, feature_col_2, target_col)\n",
    "    # Layer 1\n",
    "    feature_num = feature_col_2 - feature_col_1\n",
    "    lstm_model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train_scaled.shape[1], feature_num))\n",
    "    )\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 2\n",
    "    lstm_model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 3\n",
    "    lstm_model.add(LSTM(units=number_units))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Output layer\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    # Compile the lstm_model\n",
    "    lstm_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the lstm_model\n",
    "    lstm_model.fit(X_train_scaled, y_train_scaled, epochs=10, shuffle=False, batch_size=1, verbose=1)\n",
    "    return lstm_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1110/1110 [==============================] - 8s 3ms/step - loss: 0.0051\n",
      "Epoch 2/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 3/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 4/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 5/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0060\n",
      "Epoch 6/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0058\n",
      "Epoch 7/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 8/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0057\n",
      "Epoch 9/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0056\n",
      "Epoch 10/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x251fc3676c8>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model(df,5,0,7,7,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_evaluation(df, window,feature_col_1, feature_col_2, target_col, number_units):\n",
    "    '''\n",
    "    This function evaluates the 3d LSTM model\n",
    "    '''\n",
    "    _, X_test_scaled, _, y_test_scaled,_ =data_splited_scaled(df, window, feature_col_1, feature_col_2, target_col)\n",
    "    model = lstm_model(df, window, feature_col_1, feature_col_2, target_col, number_units)\n",
    "    score = model.evaluate(X_test_scaled, y_test_scaled,verbose=0)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1110/1110 [==============================] - 8s 4ms/step - loss: 0.0053\n",
      "Epoch 2/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0063\n",
      "Epoch 3/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0064\n",
      "Epoch 4/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 5/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 6/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 7/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 8/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0059\n",
      "Epoch 9/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0057\n",
      "Epoch 10/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.022871877998113632"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_evaluation(df,5,0,7,7,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_prediction(df, window, feature_col_1, feature_col_2, target_col, number_units):\n",
    "    '''\n",
    "    This function predicts y values and recover the original prices, and then creates a dataframe of Acural and Predicted values of y\n",
    "    '''\n",
    "    _, X_test_scaled, _, y_test_scaled,scaler =data_splited_scaled(df, window, feature_col_1, feature_col_2, target_col)\n",
    "    model= lstm_model(df, window, feature_col_1, feature_col_2, target_col, number_units)\n",
    "    y_predicted = model.predict(X_test_scaled)\n",
    "\n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = scaler.inverse_transform(y_predicted)\n",
    "    actual_prices = scaler.inverse_transform(y_test_scaled.reshape(-1, 1))\n",
    "\n",
    "    prediction_df = pd.DataFrame({\n",
    "        \"actual\":actual_prices.ravel(),\n",
    "        \"predicted\":predicted_prices.ravel(),\n",
    "    })\n",
    "    \n",
    "    return prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1110/1110 [==============================] - 8s 4ms/step - loss: 0.0049\n",
      "Epoch 2/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0061\n",
      "Epoch 3/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 4/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0062\n",
      "Epoch 5/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0061\n",
      "Epoch 6/10\n",
      "1110/1110 [==============================] - 4s 3ms/step - loss: 0.0059\n",
      "Epoch 7/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0060\n",
      "Epoch 8/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0057\n",
      "Epoch 9/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0060\n",
      "Epoch 10/10\n",
      "1110/1110 [==============================] - 4s 4ms/step - loss: 0.0052\n",
      "15/15 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.270</td>\n",
       "      <td>6.427706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.120</td>\n",
       "      <td>6.658632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.720</td>\n",
       "      <td>6.685344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.225</td>\n",
       "      <td>6.702477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.120</td>\n",
       "      <td>6.644905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>5.880</td>\n",
       "      <td>6.317099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>6.700</td>\n",
       "      <td>6.459174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>4.550</td>\n",
       "      <td>6.518028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>5.850</td>\n",
       "      <td>6.658626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>6.230</td>\n",
       "      <td>6.751138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>477 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "0     5.270   6.427706\n",
       "1     4.120   6.658632\n",
       "2     7.720   6.685344\n",
       "3     8.225   6.702477\n",
       "4    12.120   6.644905\n",
       "..      ...        ...\n",
       "472   5.880   6.317099\n",
       "473   6.700   6.459174\n",
       "474   4.550   6.518028\n",
       "475   5.850   6.658626\n",
       "476   6.230   6.751138\n",
       "\n",
       "[477 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df = lstm_prediction(df,5,0,7,7,64)\n",
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4D LSTM Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, chunk_rows, feature_col_1, feature_col_2, target_col):\n",
    "    X_list = df.iloc[:,feature_col_1:feature_col_2].values.tolist()\n",
    "    X_chunks=[X_list[i:i + chunk_rows] for i in range(0, len(X_list), chunk_rows)]\n",
    "    X = [X_chunks[i:i+window] for i in range (len(X_chunks)-window)]\n",
    "    y_list=df.iloc[:,target_col].values.tolist()\n",
    "    y_chunks = [y_list[i + chunk_rows-1] for i in range(0, len(y_list), chunk_rows)]\n",
    "    y = [y_chunks[i+window] for i in range(len(y_chunks)-window)]\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[2.09200000e+02 2.09729500e+02 2.07200000e+02 2.08270000e+02\n",
      "    1.02027111e+08 3.74705000e+05 2.08276128e+02 2.52950000e+00\n",
      "    1.56500000e+01 1.71800000e+01 1.55800000e+01 1.58400000e+01]\n",
      "   [2.06480000e+02 2.08289000e+02 2.05780000e+02 2.06990000e+02\n",
      "    1.03372367e+08 3.87782000e+05 2.06966276e+02 2.50900000e+00\n",
      "    1.76900000e+01 1.83300000e+01 1.65200000e+01 1.76000000e+01]\n",
      "   [2.06200000e+02 2.08680000e+02 2.04180000e+02 2.05330000e+02\n",
      "    1.62401537e+08 5.86210000e+05 2.06034646e+02 4.50000000e+00\n",
      "    1.80500000e+01 2.01300000e+01 1.57200000e+01 1.96100000e+01]\n",
      "   [2.05440000e+02 2.07430000e+02 2.05140000e+02 2.05860000e+02\n",
      "    1.16128858e+08 4.04992000e+05 2.06102975e+02 2.29000000e+00\n",
      "    1.92500000e+01 1.97200000e+01 1.81300000e+01 1.93400000e+01]\n",
      "   [2.03380000e+02 2.04140000e+02 2.01510000e+02 2.01880000e+02\n",
      "    2.11173305e+08 6.69924000e+05 2.03150102e+02 4.35000000e+00\n",
      "    2.13600000e+01 2.52700000e+01 2.08800000e+01 2.43900000e+01]]\n",
      "\n",
      "  [[1.93050000e+02 1.93410000e+02 1.89820000e+02 1.92110000e+02\n",
      "    1.87941153e+08 7.01513000e+05 1.91722893e+02 3.59000000e+00\n",
      "    2.55800000e+01 2.73900000e+01 2.38300000e+01 2.43000000e+01]\n",
      "   [1.93850000e+02 1.94550000e+02 1.91140000e+02 1.93660000e+02\n",
      "    1.72330490e+08 6.35729000e+05 1.92886816e+02 3.41000000e+00\n",
      "    2.29700000e+01 2.39300000e+01 2.19100000e+01 2.24700000e+01]\n",
      "   [1.94530000e+02 1.94860000e+02 1.88380000e+02 1.88870000e+02\n",
      "    2.21154886e+08 8.12684000e+05 1.91150016e+02 6.48000000e+00\n",
      "    2.17200000e+01 2.61100000e+01 2.14400000e+01 2.52200000e+01]\n",
      "   [1.89550000e+02 1.93260000e+02 1.87660000e+02 1.91890000e+02\n",
      "    2.40795609e+08 8.24310000e+05 1.90766957e+02 5.60000000e+00\n",
      "    2.47500000e+01 2.62800000e+01 2.30700000e+01 2.39500000e+01]\n",
      "   [1.86790000e+02 1.88760000e+02 1.85520000e+02 1.87830000e+02\n",
      "    3.24846447e+08 1.10555800e+06 1.87716756e+02 6.37000000e+00\n",
      "    2.89600000e+01 3.09500000e+01 2.66700000e+01 2.70200000e+01]]\n",
      "\n",
      "  [[1.92500000e+02 1.94580000e+02 1.91840000e+02 1.93650000e+02\n",
      "    1.36020564e+08 4.88404000e+05 1.93291340e+02 2.74000000e+00\n",
      "    2.13200000e+01 2.36600000e+01 1.96100000e+01 1.99800000e+01]\n",
      "   [1.91900000e+02 1.91970000e+02 1.89540000e+02 1.90110000e+02\n",
      "    1.80286395e+08 5.75167000e+05 1.91197022e+02 4.11000000e+00\n",
      "    2.13400000e+01 2.24200000e+01 2.10600000e+01 2.19800000e+01]\n",
      "   [1.91370000e+02 1.91780000e+02 1.87100000e+02 1.91230000e+02\n",
      "    2.05042020e+08 8.85125000e+05 1.89593254e+02 4.68000000e+00\n",
      "    2.14900000e+01 2.77000000e+01 2.14200000e+01 2.16500000e+01]\n",
      "   [1.90720000e+02 1.92750000e+02 1.89960000e+02 1.91530000e+02\n",
      "    1.39516454e+08 6.37999000e+05 1.91258528e+02 2.79000000e+00\n",
      "    2.22900000e+01 2.31400000e+01 2.12400000e+01 2.18400000e+01]\n",
      "   [1.90970000e+02 1.91669600e+02 1.87200000e+02 1.87980000e+02\n",
      "    1.80777333e+08 6.67127000e+05 1.88840243e+02 4.46960000e+00\n",
      "    2.20900000e+01 2.41100000e+01 2.19100000e+01 2.33800000e+01]]]\n",
      "\n",
      "\n",
      " [[[1.93050000e+02 1.93410000e+02 1.89820000e+02 1.92110000e+02\n",
      "    1.87941153e+08 7.01513000e+05 1.91722893e+02 3.59000000e+00\n",
      "    2.55800000e+01 2.73900000e+01 2.38300000e+01 2.43000000e+01]\n",
      "   [1.93850000e+02 1.94550000e+02 1.91140000e+02 1.93660000e+02\n",
      "    1.72330490e+08 6.35729000e+05 1.92886816e+02 3.41000000e+00\n",
      "    2.29700000e+01 2.39300000e+01 2.19100000e+01 2.24700000e+01]\n",
      "   [1.94530000e+02 1.94860000e+02 1.88380000e+02 1.88870000e+02\n",
      "    2.21154886e+08 8.12684000e+05 1.91150016e+02 6.48000000e+00\n",
      "    2.17200000e+01 2.61100000e+01 2.14400000e+01 2.52200000e+01]\n",
      "   [1.89550000e+02 1.93260000e+02 1.87660000e+02 1.91890000e+02\n",
      "    2.40795609e+08 8.24310000e+05 1.90766957e+02 5.60000000e+00\n",
      "    2.47500000e+01 2.62800000e+01 2.30700000e+01 2.39500000e+01]\n",
      "   [1.86790000e+02 1.88760000e+02 1.85520000e+02 1.87830000e+02\n",
      "    3.24846447e+08 1.10555800e+06 1.87716756e+02 6.37000000e+00\n",
      "    2.89600000e+01 3.09500000e+01 2.66700000e+01 2.70200000e+01]]\n",
      "\n",
      "  [[1.92500000e+02 1.94580000e+02 1.91840000e+02 1.93650000e+02\n",
      "    1.36020564e+08 4.88404000e+05 1.93291340e+02 2.74000000e+00\n",
      "    2.13200000e+01 2.36600000e+01 1.96100000e+01 1.99800000e+01]\n",
      "   [1.91900000e+02 1.91970000e+02 1.89540000e+02 1.90110000e+02\n",
      "    1.80286395e+08 5.75167000e+05 1.91197022e+02 4.11000000e+00\n",
      "    2.13400000e+01 2.24200000e+01 2.10600000e+01 2.19800000e+01]\n",
      "   [1.91370000e+02 1.91780000e+02 1.87100000e+02 1.91230000e+02\n",
      "    2.05042020e+08 8.85125000e+05 1.89593254e+02 4.68000000e+00\n",
      "    2.14900000e+01 2.77000000e+01 2.14200000e+01 2.16500000e+01]\n",
      "   [1.90720000e+02 1.92750000e+02 1.89960000e+02 1.91530000e+02\n",
      "    1.39516454e+08 6.37999000e+05 1.91258528e+02 2.79000000e+00\n",
      "    2.22900000e+01 2.31400000e+01 2.12400000e+01 2.18400000e+01]\n",
      "   [1.90970000e+02 1.91669600e+02 1.87200000e+02 1.87980000e+02\n",
      "    1.80777333e+08 6.67127000e+05 1.88840243e+02 4.46960000e+00\n",
      "    2.20900000e+01 2.41100000e+01 2.19100000e+01 2.33800000e+01]]\n",
      "\n",
      "  [[1.85750000e+02 1.86120000e+02 1.82800000e+02 1.85350000e+02\n",
      "    1.91479448e+08 7.69581000e+05 1.84547792e+02 5.18000000e+00\n",
      "    2.58900000e+01 2.77200000e+01 2.55600000e+01 2.60000000e+01]\n",
      "   [1.83380000e+02 1.86940000e+02 1.83200000e+02 1.85350000e+02\n",
      "    1.84247136e+08 7.86765000e+05 1.85051091e+02 3.74000000e+00\n",
      "    2.83000000e+01 2.83100000e+01 2.59900000e+01 2.65400000e+01]\n",
      "   [1.86440000e+02 1.88340000e+02 1.85120000e+02 1.85310000e+02\n",
      "    1.48213396e+08 6.57615000e+05 1.86587738e+02 3.22000000e+00\n",
      "    2.57500000e+01 2.66000000e+01 2.44700000e+01 2.62900000e+01]\n",
      "   [1.82380000e+02 1.84100000e+02 1.81090000e+02 1.83030000e+02\n",
      "    2.19055385e+08 8.77019000e+05 1.82856359e+02 4.22000000e+00\n",
      "    2.90100000e+01 3.09000000e+01 2.66700000e+01 2.81400000e+01]\n",
      "   [1.84930000e+02 1.86650000e+02 1.83960000e+02 1.86650000e+02\n",
      "    1.27135393e+08 5.22136000e+05 1.85546119e+02 3.62000000e+00\n",
      "    2.71600000e+01 2.75700000e+01 2.49200000e+01 2.54000000e+01]]]\n",
      "\n",
      "\n",
      " [[[1.92500000e+02 1.94580000e+02 1.91840000e+02 1.93650000e+02\n",
      "    1.36020564e+08 4.88404000e+05 1.93291340e+02 2.74000000e+00\n",
      "    2.13200000e+01 2.36600000e+01 1.96100000e+01 1.99800000e+01]\n",
      "   [1.91900000e+02 1.91970000e+02 1.89540000e+02 1.90110000e+02\n",
      "    1.80286395e+08 5.75167000e+05 1.91197022e+02 4.11000000e+00\n",
      "    2.13400000e+01 2.24200000e+01 2.10600000e+01 2.19800000e+01]\n",
      "   [1.91370000e+02 1.91780000e+02 1.87100000e+02 1.91230000e+02\n",
      "    2.05042020e+08 8.85125000e+05 1.89593254e+02 4.68000000e+00\n",
      "    2.14900000e+01 2.77000000e+01 2.14200000e+01 2.16500000e+01]\n",
      "   [1.90720000e+02 1.92750000e+02 1.89960000e+02 1.91530000e+02\n",
      "    1.39516454e+08 6.37999000e+05 1.91258528e+02 2.79000000e+00\n",
      "    2.22900000e+01 2.31400000e+01 2.12400000e+01 2.18400000e+01]\n",
      "   [1.90970000e+02 1.91669600e+02 1.87200000e+02 1.87980000e+02\n",
      "    1.80777333e+08 6.67127000e+05 1.88840243e+02 4.46960000e+00\n",
      "    2.20900000e+01 2.41100000e+01 2.19100000e+01 2.33800000e+01]]\n",
      "\n",
      "  [[1.85750000e+02 1.86120000e+02 1.82800000e+02 1.85350000e+02\n",
      "    1.91479448e+08 7.69581000e+05 1.84547792e+02 5.18000000e+00\n",
      "    2.58900000e+01 2.77200000e+01 2.55600000e+01 2.60000000e+01]\n",
      "   [1.83380000e+02 1.86940000e+02 1.83200000e+02 1.85350000e+02\n",
      "    1.84247136e+08 7.86765000e+05 1.85051091e+02 3.74000000e+00\n",
      "    2.83000000e+01 2.83100000e+01 2.59900000e+01 2.65400000e+01]\n",
      "   [1.86440000e+02 1.88340000e+02 1.85120000e+02 1.85310000e+02\n",
      "    1.48213396e+08 6.57615000e+05 1.86587738e+02 3.22000000e+00\n",
      "    2.57500000e+01 2.66000000e+01 2.44700000e+01 2.62900000e+01]\n",
      "   [1.82380000e+02 1.84100000e+02 1.81090000e+02 1.83030000e+02\n",
      "    2.19055385e+08 8.77019000e+05 1.82856359e+02 4.22000000e+00\n",
      "    2.90100000e+01 3.09000000e+01 2.66700000e+01 2.81400000e+01]\n",
      "   [1.84930000e+02 1.86650000e+02 1.83960000e+02 1.86650000e+02\n",
      "    1.27135393e+08 5.22136000e+05 1.85546119e+02 3.62000000e+00\n",
      "    2.71600000e+01 2.75700000e+01 2.49200000e+01 2.54000000e+01]]\n",
      "\n",
      "  [[1.95080000e+02 1.96230000e+02 1.93330000e+02 1.93560000e+02\n",
      "    1.25918102e+08 4.28038000e+05 1.94734889e+02 2.90000000e+00\n",
      "    2.04900000e+01 2.08100000e+01 1.83800000e+01 2.05500000e+01]\n",
      "   [1.95050000e+02 1.98210000e+02 1.94454200e+02 1.98210000e+02\n",
      "    1.41717187e+08 4.95954000e+05 1.96577646e+02 4.65000000e+00\n",
      "    1.98400000e+01 2.01700000e+01 1.76600000e+01 1.77000000e+01]\n",
      "   [1.97700000e+02 1.99060000e+02 1.97250000e+02 1.99030000e+02\n",
      "    1.02390960e+08 4.24653000e+05 1.98212177e+02 1.81000000e+00\n",
      "    1.79800000e+01 1.84100000e+01 1.67800000e+01 1.70900000e+01]\n",
      "   [1.98700000e+02 1.99795000e+02 1.98110000e+02 1.99770000e+02\n",
      "    9.51481970e+07 3.72922000e+05 1.98974279e+02 1.68500000e+00\n",
      "    1.72500000e+01 1.75600000e+01 1.63200000e+01 1.67000000e+01]\n",
      "   [2.00000000e+02 2.01350000e+02 1.99030000e+02 2.00360000e+02\n",
      "    1.28913601e+08 4.97912000e+05 2.00262675e+02 2.32000000e+00\n",
      "    1.64800000e+01 1.73500000e+01 1.60500000e+01 1.68600000e+01]]]\n",
      "\n",
      "\n",
      " [[[1.85750000e+02 1.86120000e+02 1.82800000e+02 1.85350000e+02\n",
      "    1.91479448e+08 7.69581000e+05 1.84547792e+02 5.18000000e+00\n",
      "    2.58900000e+01 2.77200000e+01 2.55600000e+01 2.60000000e+01]\n",
      "   [1.83380000e+02 1.86940000e+02 1.83200000e+02 1.85350000e+02\n",
      "    1.84247136e+08 7.86765000e+05 1.85051091e+02 3.74000000e+00\n",
      "    2.83000000e+01 2.83100000e+01 2.59900000e+01 2.65400000e+01]\n",
      "   [1.86440000e+02 1.88340000e+02 1.85120000e+02 1.85310000e+02\n",
      "    1.48213396e+08 6.57615000e+05 1.86587738e+02 3.22000000e+00\n",
      "    2.57500000e+01 2.66000000e+01 2.44700000e+01 2.62900000e+01]\n",
      "   [1.82380000e+02 1.84100000e+02 1.81090000e+02 1.83030000e+02\n",
      "    2.19055385e+08 8.77019000e+05 1.82856359e+02 4.22000000e+00\n",
      "    2.90100000e+01 3.09000000e+01 2.66700000e+01 2.81400000e+01]\n",
      "   [1.84930000e+02 1.86650000e+02 1.83960000e+02 1.86650000e+02\n",
      "    1.27135393e+08 5.22136000e+05 1.85546119e+02 3.62000000e+00\n",
      "    2.71600000e+01 2.75700000e+01 2.49200000e+01 2.54000000e+01]]\n",
      "\n",
      "  [[1.95080000e+02 1.96230000e+02 1.93330000e+02 1.93560000e+02\n",
      "    1.25918102e+08 4.28038000e+05 1.94734889e+02 2.90000000e+00\n",
      "    2.04900000e+01 2.08100000e+01 1.83800000e+01 2.05500000e+01]\n",
      "   [1.95050000e+02 1.98210000e+02 1.94454200e+02 1.98210000e+02\n",
      "    1.41717187e+08 4.95954000e+05 1.96577646e+02 4.65000000e+00\n",
      "    1.98400000e+01 2.01700000e+01 1.76600000e+01 1.77000000e+01]\n",
      "   [1.97700000e+02 1.99060000e+02 1.97250000e+02 1.99030000e+02\n",
      "    1.02390960e+08 4.24653000e+05 1.98212177e+02 1.81000000e+00\n",
      "    1.79800000e+01 1.84100000e+01 1.67800000e+01 1.70900000e+01]\n",
      "   [1.98700000e+02 1.99795000e+02 1.98110000e+02 1.99770000e+02\n",
      "    9.51481970e+07 3.72922000e+05 1.98974279e+02 1.68500000e+00\n",
      "    1.72500000e+01 1.75600000e+01 1.63200000e+01 1.67000000e+01]\n",
      "   [2.00000000e+02 2.01350000e+02 1.99030000e+02 2.00360000e+02\n",
      "    1.28913601e+08 4.97912000e+05 2.00262675e+02 2.32000000e+00\n",
      "    1.64800000e+01 1.73500000e+01 1.60500000e+01 1.68600000e+01]]\n",
      "\n",
      "  [[1.99400000e+02 2.01070000e+02 1.99250000e+02 2.00630000e+02\n",
      "    9.94755980e+07 3.76251000e+05 2.00193222e+02 1.82000000e+00\n",
      "    1.79800000e+01 1.80400000e+01 1.68700000e+01 1.73500000e+01]\n",
      "   [1.99300000e+02 1.99920000e+02 1.98210000e+02 1.98360000e+02\n",
      "    1.23944866e+08 5.03025000e+05 1.99104781e+02 2.42000000e+00\n",
      "    1.83800000e+01 1.88900000e+01 1.78200000e+01 1.86700000e+01]\n",
      "   [1.99360000e+02 1.99790000e+02 1.98430000e+02 1.99410000e+02\n",
      "    9.48012130e+07 3.66549000e+05 1.99179887e+02 1.43000000e+00\n",
      "    1.85600000e+01 1.91100000e+01 1.83100000e+01 1.83400000e+01]\n",
      "   [1.99900000e+02 2.01070000e+02 1.97380000e+02 1.99540000e+02\n",
      "    1.56838697e+08 6.29930000e+05 1.99208535e+02 3.69000000e+00\n",
      "    1.81700000e+01 1.95900000e+01 1.70600000e+01 1.80500000e+01]\n",
      "   [2.01250000e+02 2.02810000e+02 1.99517900e+02 2.02760000e+02\n",
      "    1.37454028e+08 4.26275000e+05 2.01737210e+02 3.29210000e+00\n",
      "    1.70900000e+01 1.72700000e+01 1.62800000e+01 1.65000000e+01]]]\n",
      "\n",
      "\n",
      " [[[1.95080000e+02 1.96230000e+02 1.93330000e+02 1.93560000e+02\n",
      "    1.25918102e+08 4.28038000e+05 1.94734889e+02 2.90000000e+00\n",
      "    2.04900000e+01 2.08100000e+01 1.83800000e+01 2.05500000e+01]\n",
      "   [1.95050000e+02 1.98210000e+02 1.94454200e+02 1.98210000e+02\n",
      "    1.41717187e+08 4.95954000e+05 1.96577646e+02 4.65000000e+00\n",
      "    1.98400000e+01 2.01700000e+01 1.76600000e+01 1.77000000e+01]\n",
      "   [1.97700000e+02 1.99060000e+02 1.97250000e+02 1.99030000e+02\n",
      "    1.02390960e+08 4.24653000e+05 1.98212177e+02 1.81000000e+00\n",
      "    1.79800000e+01 1.84100000e+01 1.67800000e+01 1.70900000e+01]\n",
      "   [1.98700000e+02 1.99795000e+02 1.98110000e+02 1.99770000e+02\n",
      "    9.51481970e+07 3.72922000e+05 1.98974279e+02 1.68500000e+00\n",
      "    1.72500000e+01 1.75600000e+01 1.63200000e+01 1.67000000e+01]\n",
      "   [2.00000000e+02 2.01350000e+02 1.99030000e+02 2.00360000e+02\n",
      "    1.28913601e+08 4.97912000e+05 2.00262675e+02 2.32000000e+00\n",
      "    1.64800000e+01 1.73500000e+01 1.60500000e+01 1.68600000e+01]]\n",
      "\n",
      "  [[1.99400000e+02 2.01070000e+02 1.99250000e+02 2.00630000e+02\n",
      "    9.94755980e+07 3.76251000e+05 2.00193222e+02 1.82000000e+00\n",
      "    1.79800000e+01 1.80400000e+01 1.68700000e+01 1.73500000e+01]\n",
      "   [1.99300000e+02 1.99920000e+02 1.98210000e+02 1.98360000e+02\n",
      "    1.23944866e+08 5.03025000e+05 1.99104781e+02 2.42000000e+00\n",
      "    1.83800000e+01 1.88900000e+01 1.78200000e+01 1.86700000e+01]\n",
      "   [1.99360000e+02 1.99790000e+02 1.98430000e+02 1.99410000e+02\n",
      "    9.48012130e+07 3.66549000e+05 1.99179887e+02 1.43000000e+00\n",
      "    1.85600000e+01 1.91100000e+01 1.83100000e+01 1.83400000e+01]\n",
      "   [1.99900000e+02 2.01070000e+02 1.97380000e+02 1.99540000e+02\n",
      "    1.56838697e+08 6.29930000e+05 1.99208535e+02 3.69000000e+00\n",
      "    1.81700000e+01 1.95900000e+01 1.70600000e+01 1.80500000e+01]\n",
      "   [2.01250000e+02 2.02810000e+02 1.99517900e+02 2.02760000e+02\n",
      "    1.37454028e+08 4.26275000e+05 2.01737210e+02 3.29210000e+00\n",
      "    1.70900000e+01 1.72700000e+01 1.62800000e+01 1.65000000e+01]]\n",
      "\n",
      "  [[2.02200000e+02 2.03040000e+02 2.01770000e+02 2.02530000e+02\n",
      "    7.36119490e+07 2.97691000e+05 2.02469856e+02 1.27000000e+00\n",
      "    1.70100000e+01 1.76700000e+01 1.66900000e+01 1.69200000e+01]\n",
      "   [2.01320000e+02 2.02530700e+02 2.01050000e+02 2.02200000e+02\n",
      "    9.31690580e+07 3.22270000e+05 2.01789674e+02 1.48070000e+00\n",
      "    1.76000000e+01 1.78500000e+01 1.68400000e+01 1.68400000e+01]\n",
      "   [2.01620000e+02 2.03820000e+02 2.01550000e+02 2.03390000e+02\n",
      "    1.28552379e+08 4.97345000e+05 2.02720820e+02 2.27000000e+00\n",
      "    1.59600000e+01 1.63300000e+01 1.48900000e+01 1.49900000e+01]\n",
      "   [2.03260000e+02 2.05230000e+02 2.02770000e+02 2.04790000e+02\n",
      "    1.34255005e+08 4.24808000e+05 2.04192743e+02 2.46000000e+00\n",
      "    1.53400000e+01 1.53800000e+01 1.38200000e+01 1.44400000e+01]\n",
      "   [2.04200000e+02 2.04780000e+02 2.03800000e+02 2.04520000e+02\n",
      "    1.38370904e+08 4.49462000e+05 2.04331645e+02 9.90000000e-01\n",
      "    1.40500000e+01 1.43600000e+01 1.37500000e+01 1.40200000e+01]]]]\n",
      "[18.31   18.94   13.9    17.1818 29.07  ]\n"
     ]
    }
   ],
   "source": [
    "X, y =window_data(df,3,5,0,12,12)\n",
    "print(X[0:5])\n",
    "print(y[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_splited_scaled(df, window, chunk_rows, feature_col_1,feature_col_2, target_col):\n",
    "    '''\n",
    "    This function splits X and y into training and testing sets, scales the data with MinMaxScaler and reshapes features data for the LSTM model .\n",
    "    '''\n",
    "    X, y = window_data(df, window, chunk_rows, feature_col_1,feature_col_2, target_col)\n",
    "    # Use 70% of the data for training and the remainder for testing\n",
    "    split = int(0.7 * len(X))\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training feature data X_train\n",
    "    X_scaler = scaler.fit(X_train.ravel().reshape(-1,1))\n",
    "\n",
    "    # Scale the features training and testing sets\n",
    "    X_train_scaled= X_scaler.transform(X_train.ravel().reshape(-1,1))\n",
    "    X_test_scaled = X_scaler.transform(X_test.ravel().reshape(-1,1))\n",
    "\n",
    "    # Fit the MinMaxScaler object with the training target data y_train\n",
    "    y_scaler = scaler.fit(y_train.ravel().reshape(-1,1))\n",
    "\n",
    "    # Scale the target training and testing sets\n",
    "    y_train_scaled = y_scaler.transform(y_train.ravel().reshape(-1,1))\n",
    "    y_test_scaled = y_scaler.transform(y_test.ravel().reshape(-1,1))\n",
    "\n",
    "    # Reshape the features for the model\n",
    "    feature_num = feature_col_2 - feature_col_1\n",
    "    X_train_scaled = X_train_scaled.reshape((X_train.shape[0], X_train.shape[1],X_train.shape[2], feature_num))\n",
    "    X_test_scaled = X_test_scaled.reshape((X_test.shape[0], X_test.shape[1],X_train.shape[2], feature_num))\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 3, 5, 12)\n",
      "(63, 3, 5, 12)\n",
      "(145, 1)\n",
      "(63, 1)\n",
      "[[[[5.29315825e-07 5.30658449e-07 5.24244535e-07 5.26957675e-07\n",
      "    2.58704499e-01 9.50117595e-04 5.26973214e-07 5.27287309e-09\n",
      "    3.85417990e-08 4.24213353e-08 3.83643038e-08 3.90235715e-08]\n",
      "   [5.22418871e-07 5.27005852e-07 5.20643920e-07 5.23712050e-07\n",
      "    2.62115590e-01 9.83276220e-04 5.23651894e-07 5.22089237e-09\n",
      "    4.37145141e-08 4.53373267e-08 4.07478098e-08 4.34863061e-08]\n",
      "   [5.21708891e-07 5.27997289e-07 5.16586888e-07 5.19502880e-07\n",
      "    4.11792590e-01 1.48641912e-03 5.21289612e-07 1.02693609e-08\n",
      "    4.46273462e-08 4.99014871e-08 3.87192941e-08 4.85829519e-08]\n",
      "   [5.19781801e-07 5.24827734e-07 5.19021107e-07 5.20846772e-07\n",
      "    2.94461519e-01 1.02691466e-03 5.21462870e-07 4.66558619e-09\n",
      "    4.76701198e-08 4.88618728e-08 4.48301978e-08 4.78983278e-08]\n",
      "   [5.14558373e-07 5.16485463e-07 5.09816717e-07 5.10754906e-07\n",
      "    5.35460464e-01 1.69868808e-03 5.13975433e-07 9.88901421e-09\n",
      "    5.30203300e-08 6.29347007e-08 5.18032206e-08 6.07033334e-08]]\n",
      "\n",
      "  [[4.88365163e-07 4.89277995e-07 4.80175031e-07 4.85981657e-07\n",
      "    4.76551982e-01 1.77878656e-03 4.85000092e-07 7.96192426e-09\n",
      "    6.37207505e-08 6.83102674e-08 5.92833724e-08 6.04751254e-08]\n",
      "   [4.90393679e-07 4.92168630e-07 4.83522082e-07 4.89911907e-07\n",
      "    4.36968887e-01 1.61198171e-03 4.87951387e-07 7.50550822e-09\n",
      "    5.71027180e-08 5.95369368e-08 5.44149346e-08 5.58348956e-08]\n",
      "   [4.92117917e-07 4.92954680e-07 4.76523703e-07 4.77766169e-07\n",
      "    5.60770207e-01 2.06067671e-03 4.83547479e-07 1.52899374e-08\n",
      "    5.39331621e-08 6.50646422e-08 5.32231816e-08 6.28079185e-08]\n",
      "   [4.79490407e-07 4.88897649e-07 4.74698039e-07 4.85423815e-07\n",
      "    6.10572101e-01 2.09015612e-03 4.82576177e-07 1.30585700e-08\n",
      "    6.16161655e-08 6.54957018e-08 5.73562824e-08 5.95876497e-08]\n",
      "   [4.72492028e-07 4.77487248e-07 4.69271759e-07 4.75129098e-07\n",
      "    8.23695161e-01 2.80330111e-03 4.74841952e-07 1.50110164e-08\n",
      "    7.22912295e-08 7.73371624e-08 6.64846032e-08 6.73720789e-08]]\n",
      "\n",
      "  [[4.86970559e-07 4.92244700e-07 4.85297033e-07 4.89886550e-07\n",
      "    3.44899817e-01 1.23841786e-03 4.88977116e-07 5.80662629e-09\n",
      "    5.29189042e-08 5.88523128e-08 4.85829519e-08 4.95211404e-08]\n",
      "   [4.85449172e-07 4.85626667e-07 4.79465051e-07 4.80910368e-07\n",
      "    4.57142235e-01 1.45841800e-03 4.83666670e-07 9.28045949e-09\n",
      "    5.29696171e-08 5.57081134e-08 5.22596366e-08 5.45924297e-08]\n",
      "   [4.84105280e-07 4.85144895e-07 4.73278078e-07 4.83750290e-07\n",
      "    5.19913704e-01 2.24436135e-03 4.79600084e-07 1.07257770e-08\n",
      "    5.33499638e-08 6.90963172e-08 5.31724687e-08 5.37556670e-08]\n",
      "   [4.82457111e-07 4.87604470e-07 4.80530021e-07 4.84510983e-07\n",
      "    3.53764152e-01 1.61773762e-03 4.83822627e-07 5.93340853e-09\n",
      "    5.53784796e-08 5.75337775e-08 5.27160527e-08 5.42374395e-08]\n",
      "   [4.83091022e-07 4.84864959e-07 4.73531642e-07 4.75509445e-07\n",
      "    4.58387080e-01 1.69159588e-03 4.77690715e-07 1.01922773e-08\n",
      "    5.48713506e-08 5.99933529e-08 5.44149346e-08 5.81423323e-08]]]\n",
      "\n",
      "\n",
      " [[[4.88365163e-07 4.89277995e-07 4.80175031e-07 4.85981657e-07\n",
      "    4.76551982e-01 1.77878656e-03 4.85000092e-07 7.96192426e-09\n",
      "    6.37207505e-08 6.83102674e-08 5.92833724e-08 6.04751254e-08]\n",
      "   [4.90393679e-07 4.92168630e-07 4.83522082e-07 4.89911907e-07\n",
      "    4.36968887e-01 1.61198171e-03 4.87951387e-07 7.50550822e-09\n",
      "    5.71027180e-08 5.95369368e-08 5.44149346e-08 5.58348956e-08]\n",
      "   [4.92117917e-07 4.92954680e-07 4.76523703e-07 4.77766169e-07\n",
      "    5.60770207e-01 2.06067671e-03 4.83547479e-07 1.52899374e-08\n",
      "    5.39331621e-08 6.50646422e-08 5.32231816e-08 6.28079185e-08]\n",
      "   [4.79490407e-07 4.88897649e-07 4.74698039e-07 4.85423815e-07\n",
      "    6.10572101e-01 2.09015612e-03 4.82576177e-07 1.30585700e-08\n",
      "    6.16161655e-08 6.54957018e-08 5.73562824e-08 5.95876497e-08]\n",
      "   [4.72492028e-07 4.77487248e-07 4.69271759e-07 4.75129098e-07\n",
      "    8.23695161e-01 2.80330111e-03 4.74841952e-07 1.50110164e-08\n",
      "    7.22912295e-08 7.73371624e-08 6.64846032e-08 6.73720789e-08]]\n",
      "\n",
      "  [[4.86970559e-07 4.92244700e-07 4.85297033e-07 4.89886550e-07\n",
      "    3.44899817e-01 1.23841786e-03 4.88977116e-07 5.80662629e-09\n",
      "    5.29189042e-08 5.88523128e-08 4.85829519e-08 4.95211404e-08]\n",
      "   [4.85449172e-07 4.85626667e-07 4.79465051e-07 4.80910368e-07\n",
      "    4.57142235e-01 1.45841800e-03 4.83666670e-07 9.28045949e-09\n",
      "    5.29696171e-08 5.57081134e-08 5.22596366e-08 5.45924297e-08]\n",
      "   [4.84105280e-07 4.85144895e-07 4.73278078e-07 4.83750290e-07\n",
      "    5.19913704e-01 2.24436135e-03 4.79600084e-07 1.07257770e-08\n",
      "    5.33499638e-08 6.90963172e-08 5.31724687e-08 5.37556670e-08]\n",
      "   [4.82457111e-07 4.87604470e-07 4.80530021e-07 4.84510983e-07\n",
      "    3.53764152e-01 1.61773762e-03 4.83822627e-07 5.93340853e-09\n",
      "    5.53784796e-08 5.75337775e-08 5.27160527e-08 5.42374395e-08]\n",
      "   [4.83091022e-07 4.84864959e-07 4.73531642e-07 4.75509445e-07\n",
      "    4.58387080e-01 1.69159588e-03 4.77690715e-07 1.01922773e-08\n",
      "    5.48713506e-08 5.99933529e-08 5.44149346e-08 5.81423323e-08]]\n",
      "\n",
      "  [[4.69854957e-07 4.70793146e-07 4.62374805e-07 4.68840699e-07\n",
      "    4.85523840e-01 1.95138282e-03 4.66806585e-07 1.19935993e-08\n",
      "    6.45068004e-08 6.91470301e-08 6.36700376e-08 6.47857213e-08]\n",
      "   [4.63845479e-07 4.72872374e-07 4.63389063e-07 4.68840699e-07\n",
      "    4.67185267e-01 1.99495534e-03 4.68082772e-07 8.34227096e-09\n",
      "    7.06177040e-08 7.06430605e-08 6.47603649e-08 6.61549694e-08]\n",
      "   [4.71604552e-07 4.76422277e-07 4.68257501e-07 4.68739274e-07\n",
      "    3.75816506e-01 1.66747683e-03 4.71979163e-07 7.02373573e-09\n",
      "    6.41518101e-08 6.63071081e-08 6.09061850e-08 6.55210583e-08]\n",
      "   [4.61309835e-07 4.65671144e-07 4.58038853e-07 4.62958004e-07\n",
      "    5.55446618e-01 2.22380741e-03 4.62517712e-07 9.55938040e-09\n",
      "    7.24180118e-08 7.72103802e-08 6.64846032e-08 7.02120009e-08]\n",
      "   [4.67775729e-07 4.72137037e-07 4.65316153e-07 4.72137037e-07\n",
      "    3.22370180e-01 1.32395022e-03 4.69337987e-07 8.03799360e-09\n",
      "    6.77270691e-08 6.87666834e-08 6.20472251e-08 6.32643345e-08]]]\n",
      "\n",
      "\n",
      " [[[4.86970559e-07 4.92244700e-07 4.85297033e-07 4.89886550e-07\n",
      "    3.44899817e-01 1.23841786e-03 4.88977116e-07 5.80662629e-09\n",
      "    5.29189042e-08 5.88523128e-08 4.85829519e-08 4.95211404e-08]\n",
      "   [4.85449172e-07 4.85626667e-07 4.79465051e-07 4.80910368e-07\n",
      "    4.57142235e-01 1.45841800e-03 4.83666670e-07 9.28045949e-09\n",
      "    5.29696171e-08 5.57081134e-08 5.22596366e-08 5.45924297e-08]\n",
      "   [4.84105280e-07 4.85144895e-07 4.73278078e-07 4.83750290e-07\n",
      "    5.19913704e-01 2.24436135e-03 4.79600084e-07 1.07257770e-08\n",
      "    5.33499638e-08 6.90963172e-08 5.31724687e-08 5.37556670e-08]\n",
      "   [4.82457111e-07 4.87604470e-07 4.80530021e-07 4.84510983e-07\n",
      "    3.53764152e-01 1.61773762e-03 4.83822627e-07 5.93340853e-09\n",
      "    5.53784796e-08 5.75337775e-08 5.27160527e-08 5.42374395e-08]\n",
      "   [4.83091022e-07 4.84864959e-07 4.73531642e-07 4.75509445e-07\n",
      "    4.58387080e-01 1.69159588e-03 4.77690715e-07 1.01922773e-08\n",
      "    5.48713506e-08 5.99933529e-08 5.44149346e-08 5.81423323e-08]]\n",
      "\n",
      "  [[4.69854957e-07 4.70793146e-07 4.62374805e-07 4.68840699e-07\n",
      "    4.85523840e-01 1.95138282e-03 4.66806585e-07 1.19935993e-08\n",
      "    6.45068004e-08 6.91470301e-08 6.36700376e-08 6.47857213e-08]\n",
      "   [4.63845479e-07 4.72872374e-07 4.63389063e-07 4.68840699e-07\n",
      "    4.67185267e-01 1.99495534e-03 4.68082772e-07 8.34227096e-09\n",
      "    7.06177040e-08 7.06430605e-08 6.47603649e-08 6.61549694e-08]\n",
      "   [4.71604552e-07 4.76422277e-07 4.68257501e-07 4.68739274e-07\n",
      "    3.75816506e-01 1.66747683e-03 4.71979163e-07 7.02373573e-09\n",
      "    6.41518101e-08 6.63071081e-08 6.09061850e-08 6.55210583e-08]\n",
      "   [4.61309835e-07 4.65671144e-07 4.58038853e-07 4.62958004e-07\n",
      "    5.55446618e-01 2.22380741e-03 4.62517712e-07 9.55938040e-09\n",
      "    7.24180118e-08 7.72103802e-08 6.64846032e-08 7.02120009e-08]\n",
      "   [4.67775729e-07 4.72137037e-07 4.65316153e-07 4.72137037e-07\n",
      "    3.22370180e-01 1.32395022e-03 4.69337987e-07 8.03799360e-09\n",
      "    6.77270691e-08 6.87666834e-08 6.20472251e-08 6.32643345e-08]]\n",
      "\n",
      "  [[4.93512522e-07 4.96428513e-07 4.89075144e-07 4.89658342e-07\n",
      "    3.19283563e-01 1.08535113e-03 4.92637443e-07 6.21232944e-09\n",
      "    5.08143192e-08 5.16257255e-08 4.54641089e-08 5.09664579e-08]\n",
      "   [4.93436453e-07 5.01449090e-07 4.91925716e-07 5.01449090e-07\n",
      "    3.59344429e-01 1.25756198e-03 4.97310020e-07 1.06497076e-08\n",
      "    4.91661501e-08 5.00029129e-08 4.36384448e-08 4.37398705e-08]\n",
      "   [5.00155911e-07 5.03604388e-07 4.99014871e-07 5.03528318e-07\n",
      "    2.59627091e-01 1.07676797e-03 5.01454610e-07 3.44847675e-09\n",
      "    4.44498511e-08 4.55401783e-08 4.14070774e-08 4.21931273e-08]\n",
      "   [5.02691556e-07 5.05468087e-07 5.01195525e-07 5.05404695e-07\n",
      "    2.41262017e-01 9.45596540e-04 5.03387030e-07 3.13152117e-09\n",
      "    4.25988304e-08 4.33848803e-08 4.02406809e-08 4.12042259e-08]\n",
      "   [5.05987894e-07 5.09411014e-07 5.03528318e-07 5.06900726e-07\n",
      "    3.26879084e-01 1.26252677e-03 5.06653944e-07 4.74165553e-09\n",
      "    4.06463840e-08 4.28523949e-08 3.95560568e-08 4.16099290e-08]]]\n",
      "\n",
      "\n",
      " [[[4.69854957e-07 4.70793146e-07 4.62374805e-07 4.68840699e-07\n",
      "    4.85523840e-01 1.95138282e-03 4.66806585e-07 1.19935993e-08\n",
      "    6.45068004e-08 6.91470301e-08 6.36700376e-08 6.47857213e-08]\n",
      "   [4.63845479e-07 4.72872374e-07 4.63389063e-07 4.68840699e-07\n",
      "    4.67185267e-01 1.99495534e-03 4.68082772e-07 8.34227096e-09\n",
      "    7.06177040e-08 7.06430605e-08 6.47603649e-08 6.61549694e-08]\n",
      "   [4.71604552e-07 4.76422277e-07 4.68257501e-07 4.68739274e-07\n",
      "    3.75816506e-01 1.66747683e-03 4.71979163e-07 7.02373573e-09\n",
      "    6.41518101e-08 6.63071081e-08 6.09061850e-08 6.55210583e-08]\n",
      "   [4.61309835e-07 4.65671144e-07 4.58038853e-07 4.62958004e-07\n",
      "    5.55446618e-01 2.22380741e-03 4.62517712e-07 9.55938040e-09\n",
      "    7.24180118e-08 7.72103802e-08 6.64846032e-08 7.02120009e-08]\n",
      "   [4.67775729e-07 4.72137037e-07 4.65316153e-07 4.72137037e-07\n",
      "    3.22370180e-01 1.32395022e-03 4.69337987e-07 8.03799360e-09\n",
      "    6.77270691e-08 6.87666834e-08 6.20472251e-08 6.32643345e-08]]\n",
      "\n",
      "  [[4.93512522e-07 4.96428513e-07 4.89075144e-07 4.89658342e-07\n",
      "    3.19283563e-01 1.08535113e-03 4.92637443e-07 6.21232944e-09\n",
      "    5.08143192e-08 5.16257255e-08 4.54641089e-08 5.09664579e-08]\n",
      "   [4.93436453e-07 5.01449090e-07 4.91925716e-07 5.01449090e-07\n",
      "    3.59344429e-01 1.25756198e-03 4.97310020e-07 1.06497076e-08\n",
      "    4.91661501e-08 5.00029129e-08 4.36384448e-08 4.37398705e-08]\n",
      "   [5.00155911e-07 5.03604388e-07 4.99014871e-07 5.03528318e-07\n",
      "    2.59627091e-01 1.07676797e-03 5.01454610e-07 3.44847675e-09\n",
      "    4.44498511e-08 4.55401783e-08 4.14070774e-08 4.21931273e-08]\n",
      "   [5.02691556e-07 5.05468087e-07 5.01195525e-07 5.05404695e-07\n",
      "    2.41262017e-01 9.45596540e-04 5.03387030e-07 3.13152117e-09\n",
      "    4.25988304e-08 4.33848803e-08 4.02406809e-08 4.12042259e-08]\n",
      "   [5.05987894e-07 5.09411014e-07 5.03528318e-07 5.06900726e-07\n",
      "    3.26879084e-01 1.26252677e-03 5.06653944e-07 4.74165553e-09\n",
      "    4.06463840e-08 4.28523949e-08 3.95560568e-08 4.16099290e-08]]\n",
      "\n",
      "  [[5.04466507e-07 5.08701034e-07 5.04086160e-07 5.07585350e-07\n",
      "    2.52234769e-01 9.54037701e-04 5.06477836e-07 3.47383320e-09\n",
      "    4.44498511e-08 4.46019897e-08 4.16352855e-08 4.28523949e-08]\n",
      "   [5.04212942e-07 5.05785042e-07 5.01449090e-07 5.01829437e-07\n",
      "    3.14280138e-01 1.27549152e-03 5.03717936e-07 4.99522000e-09\n",
      "    4.54641089e-08 4.67572877e-08 4.40441479e-08 4.61994459e-08]\n",
      "   [5.04365081e-07 5.05455408e-07 5.02006932e-07 5.04491863e-07\n",
      "    2.40382189e-01 9.29436877e-04 5.03908379e-07 2.48493178e-09\n",
      "    4.59205250e-08 4.73151295e-08 4.52866138e-08 4.53626831e-08]\n",
      "   [5.05734329e-07 5.08701034e-07 4.99344505e-07 5.04821497e-07\n",
      "    3.97687205e-01 1.59727751e-03 5.03981020e-07 8.21548873e-09\n",
      "    4.49316235e-08 4.85322390e-08 4.21170580e-08 4.46273462e-08]\n",
      "   [5.09157450e-07 5.13113055e-07 5.04765459e-07 5.12986273e-07\n",
      "    3.48534572e-01 1.08088079e-03 5.10392841e-07 7.20655571e-09\n",
      "    4.21931273e-08 4.26495433e-08 4.01392551e-08 4.06970969e-08]]]\n",
      "\n",
      "\n",
      " [[[4.93512522e-07 4.96428513e-07 4.89075144e-07 4.89658342e-07\n",
      "    3.19283563e-01 1.08535113e-03 4.92637443e-07 6.21232944e-09\n",
      "    5.08143192e-08 5.16257255e-08 4.54641089e-08 5.09664579e-08]\n",
      "   [4.93436453e-07 5.01449090e-07 4.91925716e-07 5.01449090e-07\n",
      "    3.59344429e-01 1.25756198e-03 4.97310020e-07 1.06497076e-08\n",
      "    4.91661501e-08 5.00029129e-08 4.36384448e-08 4.37398705e-08]\n",
      "   [5.00155911e-07 5.03604388e-07 4.99014871e-07 5.03528318e-07\n",
      "    2.59627091e-01 1.07676797e-03 5.01454610e-07 3.44847675e-09\n",
      "    4.44498511e-08 4.55401783e-08 4.14070774e-08 4.21931273e-08]\n",
      "   [5.02691556e-07 5.05468087e-07 5.01195525e-07 5.05404695e-07\n",
      "    2.41262017e-01 9.45596540e-04 5.03387030e-07 3.13152117e-09\n",
      "    4.25988304e-08 4.33848803e-08 4.02406809e-08 4.12042259e-08]\n",
      "   [5.05987894e-07 5.09411014e-07 5.03528318e-07 5.06900726e-07\n",
      "    3.26879084e-01 1.26252677e-03 5.06653944e-07 4.74165553e-09\n",
      "    4.06463840e-08 4.28523949e-08 3.95560568e-08 4.16099290e-08]]\n",
      "\n",
      "  [[5.04466507e-07 5.08701034e-07 5.04086160e-07 5.07585350e-07\n",
      "    2.52234769e-01 9.54037701e-04 5.06477836e-07 3.47383320e-09\n",
      "    4.44498511e-08 4.46019897e-08 4.16352855e-08 4.28523949e-08]\n",
      "   [5.04212942e-07 5.05785042e-07 5.01449090e-07 5.01829437e-07\n",
      "    3.14280138e-01 1.27549152e-03 5.03717936e-07 4.99522000e-09\n",
      "    4.54641089e-08 4.67572877e-08 4.40441479e-08 4.61994459e-08]\n",
      "   [5.04365081e-07 5.05455408e-07 5.02006932e-07 5.04491863e-07\n",
      "    2.40382189e-01 9.29436877e-04 5.03908379e-07 2.48493178e-09\n",
      "    4.59205250e-08 4.73151295e-08 4.52866138e-08 4.53626831e-08]\n",
      "   [5.05734329e-07 5.08701034e-07 4.99344505e-07 5.04821497e-07\n",
      "    3.97687205e-01 1.59727751e-03 5.03981020e-07 8.21548873e-09\n",
      "    4.49316235e-08 4.85322390e-08 4.21170580e-08 4.46273462e-08]\n",
      "   [5.09157450e-07 5.13113055e-07 5.04765459e-07 5.12986273e-07\n",
      "    3.48534572e-01 1.08088079e-03 5.10392841e-07 7.20655571e-09\n",
      "    4.21931273e-08 4.26495433e-08 4.01392551e-08 4.06970969e-08]]\n",
      "\n",
      "  [[5.11566312e-07 5.13696254e-07 5.10475985e-07 5.12403075e-07\n",
      "    1.86653745e-01 7.54837456e-04 5.12250571e-07 2.07922863e-09\n",
      "    4.19902757e-08 4.36638012e-08 4.11788694e-08 4.17620677e-08]\n",
      "   [5.09334945e-07 5.12404850e-07 5.08650321e-07 5.11566312e-07\n",
      "    2.36243624e-01 8.17161067e-04 5.10525871e-07 2.61348896e-09\n",
      "    4.34863061e-08 4.41202172e-08 4.15592161e-08 4.15592161e-08]\n",
      "   [5.10095638e-07 5.15674056e-07 5.09918143e-07 5.14583729e-07\n",
      "    3.25963153e-01 1.26108906e-03 5.12886926e-07 4.61487330e-09\n",
      "    3.93278488e-08 4.02660373e-08 3.66147090e-08 3.68682735e-08]\n",
      "   [5.14254095e-07 5.19249315e-07 5.13011629e-07 5.18133632e-07\n",
      "    3.40422987e-01 1.07716100e-03 5.16619200e-07 5.09664579e-09\n",
      "    3.77557491e-08 3.78571749e-08 3.39015692e-08 3.54736689e-08]\n",
      "   [5.16637601e-07 5.18108275e-07 5.15623344e-07 5.17449008e-07\n",
      "    3.50859444e-01 1.13967478e-03 5.16971406e-07 1.36924812e-09\n",
      "    3.44847675e-08 3.52708174e-08 3.37240741e-08 3.44086982e-08]]]]\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled, scaler=data_splited_scaled(df,3,5,0,12,12)\n",
    "print(X_train_scaled.shape)\n",
    "print(X_test_scaled.shape)\n",
    "print(y_train_scaled.shape)\n",
    "print(y_test_scaled.shape)\n",
    "print(X_train_scaled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lstm_model(df, window, chunk_rows, feature_col_1, feature_col_2, target_col, number_units):\n",
    "    '''\n",
    "    This function builds and trains a 3-layer LSTM model\n",
    "\n",
    "    '''\n",
    "\n",
    "    X_train_scaled, _, y_train_scaled, _ ,_= data_splited_scaled(df, window, chunk_rows, feature_col_1,feature_col_2, target_col)\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    lstm_model = Sequential()\n",
    "\n",
    "    dropout_fraction = 0.2\n",
    "    # calculate\n",
    "    X_train_scaled, _, _, _ ,_= data_splited_scaled(df, window, chunk_rows, feature_col_1, feature_col_2, target_col)\n",
    "\n",
    "    \n",
    "    # use TimeDistributed to get proper input shape of X_train\n",
    "    # Layer 1\n",
    "    lstm_model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(window, chunk_rows*(feature_col_2-feature_col_1))\n",
    "    ))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 2\n",
    "    lstm_model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Layer 3\n",
    "    lstm_model.add(LSTM(units=number_units))\n",
    "    lstm_model.add(Dropout(dropout_fraction))\n",
    "    # Output layer\n",
    "    lstm_model.add(Dense(1))\n",
    "\n",
    "    # Compile the lstm_model\n",
    "    lstm_model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the lstm_model\n",
    "    lstm_model.fit(X_train_scaled.reshape(X_train_scaled.shape[0],X_train_scaled.shape[1],-1), y_train_scaled, epochs=10, shuffle=False, batch_size=1, verbose=1)\n",
    "\n",
    "    return lstm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "145/145 [==============================] - 4s 3ms/step - loss: 0.0164\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0182\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0188\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2519c4f5588>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_model(df,3,5,0,12,12,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lstm_evaluation(df, window,chunk_rows, feature_col_1, feature_col_2, target_col, number_units):\n",
    "    '''\n",
    "    This function evaluates the LSTM model\n",
    "    '''\n",
    "    _, X_test_scaled, _, y_test_scaled,_ =data_splited_scaled(df, window,chunk_rows, feature_col_1, feature_col_2, target_col)\n",
    "    model = lstm_model(df, window, chunk_rows,feature_col_1, feature_col_2, target_col, number_units)\n",
    "    score = model.evaluate(X_test_scaled.reshape(X_test_scaled.shape[0],X_test_scaled.shape[1],-1), y_test_scaled,verbose=0)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "145/145 [==============================] - 4s 3ms/step - loss: 0.0155\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 1s 4ms/step - loss: 0.0183\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0188\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0186\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.018896009773015976"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_evaluation(df,3,5,0,12,12,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_prediction(df, window, chunk_rows, feature_col_1, feature_col_2,target_col, number_units):\n",
    "    '''\n",
    "    This function predicts y values and recover the original prices, and then creates a dataframe of Acural and Predicted values of y\n",
    "    '''\n",
    "    _, X_test_scaled, _, y_test_scaled,scaler =data_splited_scaled(df, window,chunk_rows, feature_col_1,feature_col_2, target_col)\n",
    "    model= lstm_model(df, window, chunk_rows, feature_col_1, feature_col_2, target_col, number_units)\n",
    "    y_predicted = model.predict(X_test_scaled.reshape(X_test_scaled.shape[0],X_test_scaled.shape[1],-1))\n",
    "\n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted = scaler.inverse_transform(y_predicted)\n",
    "    actual = scaler.inverse_transform(y_test_scaled.reshape(-1, 1))\n",
    "\n",
    "    prediction_df = pd.DataFrame({\n",
    "        \"actual\":actual.ravel(),\n",
    "        \"predicted\":predicted.ravel(),\n",
    "    })\n",
    "\n",
    "    return prediction_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "145/145 [==============================] - 5s 3ms/step - loss: 0.0160\n",
      "Epoch 2/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0187\n",
      "Epoch 3/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0190\n",
      "Epoch 4/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 5/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 6/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0190\n",
      "Epoch 7/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 8/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 9/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0186\n",
      "Epoch 10/10\n",
      "145/145 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "2/2 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction_df = lstm_prediction(df,3,5,0,12,12,64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.9200</td>\n",
       "      <td>9.001218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.2150</td>\n",
       "      <td>8.924905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24.8100</td>\n",
       "      <td>8.978096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.9000</td>\n",
       "      <td>9.089535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0800</td>\n",
       "      <td>9.238941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>18.3100</td>\n",
       "      <td>8.898646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>18.9400</td>\n",
       "      <td>9.098240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>13.9000</td>\n",
       "      <td>9.110842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>17.1818</td>\n",
       "      <td>9.186761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>29.0700</td>\n",
       "      <td>9.153481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "0    5.9200   9.001218\n",
       "1   18.2150   8.924905\n",
       "2   24.8100   8.978096\n",
       "3   18.9000   9.089535\n",
       "4   15.0800   9.238941\n",
       "..      ...        ...\n",
       "58  18.3100   8.898646\n",
       "59  18.9400   9.098240\n",
       "60  13.9000   9.110842\n",
       "61  17.1818   9.186761\n",
       "62  29.0700   9.153481\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting Funtions\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def history_plotting(df, title):\n",
    "\n",
    "    '''\n",
    "    This function plots the historical data.\n",
    "    '''\n",
    "\n",
    "    return df.hvplot(\n",
    "                    ylabel = 'Price in $',\n",
    "                    width= 1000,\n",
    "                    height=400,\n",
    "                    title=title)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_avgs_plotting(df,ma_column_1, ma_column_2, title):\n",
    "    '''\n",
    "    This function plots the overlay of the original prices and moving averages.\n",
    "    '''\n",
    "    prices = df['close'].hvplot(line_color='lightgray',\n",
    "                        ylabel='Price in $',\n",
    "                        width=1000,\n",
    "                        height=400,\n",
    "                        title=title\n",
    "                        )\n",
    "\n",
    "    moving_avgs = df[[ma_column_1, ma_column_2]].hvplot(\n",
    "                            ylabel='Price in $',\n",
    "                            width=1000,\n",
    "                            height=400\n",
    "    )   \n",
    "\n",
    "    return prices*moving_avgs\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_plotting(df,index, ylabel,title):\n",
    "    '''\n",
    "    This function plots the actual prices vs. the predicted values.\n",
    "    '''\n",
    "    return df[[\"actual\",\"predicted\"]].plot(\n",
    "                    ylabel= ylabel,\n",
    "                    title=title\n",
    ").axvline(index, color='red',label='prediction start')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bands_plotting(df, title ):\n",
    "#     '''\n",
    "#     This function plots the range of the prices.\n",
    "#     '''\n",
    "#     close = df['close'].hvplot(\n",
    "#         line_color=\"lightgray\",\n",
    "#         ylabel=\"Price in $\",\n",
    "#         width=1000,\n",
    "#         height=400,\n",
    "#         title=title\n",
    "#     )\n",
    "\n",
    "#     upper_band = df['upper'].hvplot(\n",
    "#         line_color=\"purple\",\n",
    "#         ylabel = \"Price in $\",\n",
    "#         width=1000,\n",
    "#         height=400,\n",
    "#     )\n",
    "\n",
    "#     middle = df['middle'].hvplot(\n",
    "#         line_color=\"orange\",\n",
    "#         ylabel = \"Price in $\",\n",
    "#         width = 1000,\n",
    "#         height = 400\n",
    "#     )\n",
    "\n",
    "\n",
    "#     lower_band = df['lower'].hvplot(\n",
    "#         line_color=\"blue\",\n",
    "#         ylabel = \"Price in $\",\n",
    "#         width = 1000,\n",
    "#         height = 400\n",
    "#     )\n",
    "\n",
    "#     # Overlay plots\n",
    "#     return close * upper_band *middle *lower_band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def entry_exit_positions(df, title):\n",
    "#     '''\n",
    "#     This function plots the entry/exit positions using ranges.\n",
    "#     '''\n",
    "#     entry = df[df[\"signal\"] == 1.0][\"close\"].hvplot.scatter(\n",
    "#     color=\"green\",\n",
    "#     marker=\"^\",\n",
    "#     size=200,\n",
    "#     legend=False,\n",
    "#     ylabel=\"Price in $\",\n",
    "#     title=title,\n",
    "#     width=1000,\n",
    "#     height=400,\n",
    "# )\n",
    "\n",
    "# # Visualize exit position relative to close price\n",
    "#     exit = df[df[\"signal\"] == -1.0][\"close\"].hvplot.scatter(\n",
    "#     color=\"red\",\n",
    "#     marker=\"v\",\n",
    "#     size=200,\n",
    "#     legend=False,\n",
    "#     ylabel=\"Price in $\",\n",
    "#     width=1000,\n",
    "#     height=400\n",
    "# )\n",
    "\n",
    "# # Visualize close price for the investment\n",
    "#     close = df[[\"close\"]].hvplot(\n",
    "#     line_color=\"lightgray\",\n",
    "#     ylabel=\"Price in $\",\n",
    "#     width=1000,\n",
    "#     height=400\n",
    "# )\n",
    "\n",
    "#     upper = df[[\"upper\"]].hvplot(\n",
    "#     line_color=\"purple\",\n",
    "#     ylabel=\"Price in $\",\n",
    "#     width=1000,\n",
    "#     height=400\n",
    "# )\n",
    "\n",
    "#     middle = df[[\"middle\"]].hvplot(\n",
    "#     line_color=\"orange\",\n",
    "#     ylabel=\"Price in $\",\n",
    "#     width=1000,\n",
    "#     height=400\n",
    "# )\n",
    "\n",
    "#     lower = df[[\"Lower\"]].hvplot(\n",
    "#     line_color=\"blue\",\n",
    "#     ylabel=\"Price in $\",\n",
    "#     width=1000,\n",
    "#     height=400\n",
    "# )\n",
    "\n",
    "\n",
    "# # Overlay plots\n",
    "#     return close * upper * middle * lower * entry * exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eda12c2122dd4de2a2eea024d65cac832728e3fb16b3b5d201b2f43f2d409343"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pyvizenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
